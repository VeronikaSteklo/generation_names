# Fine-Tuning ruT5-small for Literary Title Generation 

Эта часть проекта посвящена дообучению модели **ruT5-small** на кастомном датасете художественной литературы.

В качестве базовой модели использовалась **cointegrated/rut5-small**. 
Модель обучалась на собранном вручную датасете, содержащем пары `текст фрагмента — авторский заголовок`.

| Метрика              | Значение |
|:---------------------|:---------|
| **Final Train Loss** | 1.0067   |
| **Final Val Loss**   | 3.4765   |


Пример генерации:

**Входной текст:**
> *«Каждый из нас понимает очевидную вещь: консультация с широким активом предопределяет высокую востребованность экспериментов, поражающих по своей масштабности и грандиозности. Есть над чем задуматься: некоторые особенности внутренней политики ограничены исключительно образом мышления. Таким образом, убеждённость некоторых оппонентов создаёт необходимость включения в производственный план целого ряда внеочередных мероприятий с учётом комплекса экономической целесообразности принимаемых решений.»*

**Сгенерированный заголовок:**
> «интервью с большой стороны»
