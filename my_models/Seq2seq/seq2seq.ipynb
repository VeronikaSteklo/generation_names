{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T06:07:38.493369Z",
     "start_time": "2025-08-14T06:07:32.841518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "from io import open\n",
    "import re\n",
    "import random\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "import nltk\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "bbb7bed3664fb591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:16:03.988599Z",
     "start_time": "2025-08-04T07:16:03.642490Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('punkt')",
   "id": "500983476805736",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/veronika_steklo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-10T06:56:23.362773Z",
     "start_time": "2025-08-10T06:56:19.539350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('../data/data_tokenize.csv')\n",
    "pairs = list(dataset[[\"title\", \"text\"]].itertuples(index=False, name=None))\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)"
   ],
   "id": "d32ab7766f117c02",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:16:23.377495Z",
     "start_time": "2025-08-04T07:16:23.375639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sos_token = 0\n",
    "eos_token = 1\n",
    "MAX_VOCAB_SIZE = 30_000\n",
    "\n",
    "MAX_INPUT_LEN = 300\n",
    "MAX_TARGET_LEN = 30\n"
   ],
   "id": "494f3908570a88c1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Работа с данными",
   "id": "b19158c090ab7cd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Словарь частот",
   "id": "fc6eb2179a03ea77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:16:25.327555Z",
     "start_time": "2025-08-04T07:16:25.322161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    \"\"\"Создаёт словари с частотами слов на основе входных данных\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "        self.word2count = {\"<pad>\": 0, \"<unk>\": 0, \"<sos>\": 0, \"<eos>\": 0}\n",
    "        self.index2word = {0: \"<pad>\", 1: \"<unk>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "        self._temp_word_counts = {}\n",
    "\n",
    "    def addText(self, text: str):\n",
    "        \"\"\"Для каждого слова в тексте добавляет его во временный счётчик\"\"\"\n",
    "        for word in text.split():\n",
    "            self._temp_word_counts[word] = self._temp_word_counts.get(word, 0) + 1\n",
    "\n",
    "    def build_vocab(self, is_text: bool = False):\n",
    "        \"\"\"Строит финальный словарь после подсчёта всех слов\"\"\"\n",
    "        sorted_words = sorted(self._temp_word_counts.items(),\n",
    "                            key=lambda x: x[1],\n",
    "                            reverse=True)\n",
    "\n",
    "        for word, count in sorted_words[:MAX_VOCAB_SIZE - 4]:\n",
    "            if word not in self.word2index:\n",
    "\n",
    "                if is_text:\n",
    "                    if count > 10:\n",
    "                        self.word2index[word] = self.n_words\n",
    "                        self.word2count[word] = count\n",
    "                        self.index2word[self.n_words] = word\n",
    "                        self.n_words += 1\n",
    "                    else:\n",
    "                        self.word2count[\"<unk>\"] += count\n",
    "\n",
    "                else:\n",
    "                    if count > 5:\n",
    "                        self.word2index[word] = self.n_words\n",
    "                        self.word2count[word] = count\n",
    "                        self.index2word[self.n_words] = word\n",
    "                        self.n_words += 1\n",
    "                    else:\n",
    "                        self.word2count[\"<unk>\"] += count\n",
    "\n",
    "        for word, count in sorted_words[MAX_VOCAB_SIZE - 4:]:\n",
    "            self.word2count[\"<unk>\"] += count\n",
    "\n",
    "    def word_to_index(self, word: str) -> int:\n",
    "        \"\"\"Возвращает индекс слова или <unk>\"\"\"\n",
    "        return self.word2index.get(word, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def index_to_word(self, index: int) -> str:\n",
    "        \"\"\"Возвращает слово по индексу\"\"\"\n",
    "        return self.index2word.get(index, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def save(self, file_path: str):\n",
    "        \"\"\"Сохраняет словарь в файл\"\"\"\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'name': self.name,\n",
    "                'word2index': self.word2index,\n",
    "                'word2count': self.word2count,\n",
    "                'index2word': self.index2word,\n",
    "                'n_words': self.n_words\n",
    "            }, f)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file_path: str):\n",
    "        \"\"\"Загружает словарь из файла\"\"\"\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "\n",
    "        vocab = cls(data['name'])\n",
    "        vocab.word2index = data['word2index']\n",
    "        vocab.word2count = data['word2count']\n",
    "        vocab.index2word = data['index2word']\n",
    "        vocab.n_words = data['n_words']\n",
    "\n",
    "        return vocab\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Строковое представление словаря\"\"\"\n",
    "        return (\n",
    "            f\"Vocab(name='{self.name}', \"\n",
    "            f\"n_words={self.n_words}, \"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2index)"
   ],
   "id": "af697d8019de7b60",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:16:54.450748Z",
     "start_time": "2025-08-04T07:16:49.969132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = Vocab(\"input\")\n",
    "target_vocab = Vocab(\"target\")\n",
    "\n",
    "for title, text in train_pairs:\n",
    "    input_vocab.addText(text)\n",
    "    target_vocab.addText(title)\n",
    "\n",
    "input_vocab.build_vocab(is_text=True)\n",
    "input_vocab.save(\"../../data/vocabs/src_vocab.pkl\")\n",
    "target_vocab.build_vocab(is_text=False)\n",
    "target_vocab.save(\"../../data/vocabs/trg_vocab.pkl\")\n"
   ],
   "id": "9bd4598240aaaf2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Преобразование текста в датасет",
   "id": "30166912bd00d08f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:37.531231Z",
     "start_time": "2025-08-04T07:17:37.527059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_tensor(text: str, vocab: Vocab, add_sos_eos=True, max_len: int | None = None, truncate_from_start=False) -> torch.Tensor:\n",
    "    \"\"\"Преобразует текст в тензоры, с опциональной обрезкой\"\"\"\n",
    "    tokens = text.strip().split()\n",
    "\n",
    "    if max_len is not None:\n",
    "        if truncate_from_start:\n",
    "            tokens = tokens[-max_len:]\n",
    "        else:\n",
    "            tokens = tokens[:max_len]\n",
    "\n",
    "    indices = [vocab.word_to_index(w) for w in tokens]\n",
    "\n",
    "    if add_sos_eos:\n",
    "        indices = [vocab.word2index[\"<sos>\"]] + indices + [vocab.word2index[\"<eos>\"]]\n",
    "\n",
    "    return torch.tensor(indices, dtype=torch.long)\n"
   ],
   "id": "97e9048e47fad56b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:39.183787Z",
     "start_time": "2025-08-04T07:17:39.179262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, pairs: list[tuple[str, str]], input_vocab: Vocab, output_vocab: Vocab):\n",
    "        \"\"\"\n",
    "            pairs — список пар (название, текст),\n",
    "            input_vocab - словарь с частотами слов из текстов,\n",
    "            output_vocab - словарь с частотами слов из названий\n",
    "        \"\"\"\n",
    "        self.pairs = pairs\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title, text = self.pairs[idx]\n",
    "        input_tensor = text_to_tensor(text, self.input_vocab, add_sos_eos=False, max_len=300)\n",
    "        target_tensor = text_to_tensor(title, self.output_vocab, add_sos_eos=False, max_len=30)\n",
    "        return input_tensor, target_tensor\n"
   ],
   "id": "cd131f5993493712",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:40.349521Z",
     "start_time": "2025-08-04T07:17:40.346035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch: List[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    batch: list of (input_tensor, target_tensor)\n",
    "    Returns:\n",
    "        input_padded: [batch, src_len]\n",
    "        target_padded: [batch, trg_len]\n",
    "    \"\"\"\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_padded = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "\n",
    "    return src_padded, trg_padded\n"
   ],
   "id": "69762e8b16737afb",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Модель seq2seq",
   "id": "789cf67de81efcf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Энкодер для seq2seq",
   "id": "721ebb0bf826a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:42.045595Z",
     "start_time": "2025-08-04T07:17:42.041379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.3):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ],
   "id": "876bda39f0cca67d",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Декодер для seq2seq",
   "id": "675fe048e3c70629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:43.608904Z",
     "start_time": "2025-08-04T07:17:43.603736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ],
   "id": "a16bdbd14838a2c0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Модель",
   "id": "a48522022988539d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:42:23.129380Z",
     "start_time": "2025-08-04T07:42:23.119241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hid_dim, \"Hidden dimensions must match!\"\n",
    "        assert decoder.n_layers == 1, \"Encoder must produce compatible layers for decoder\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.1):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def train_epoch(self, dataloader, optimizer, criterion, clip=1.0):\n",
    "        self.train()\n",
    "        epoch_loss = 0\n",
    "        total_grad_norm = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(self.device)\n",
    "            trg = trg.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self(src, trg)\n",
    "            output_dim = outputs.shape[-1]\n",
    "            outputs = outputs[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, trg)\n",
    "            loss.backward()\n",
    "\n",
    "            current_grad_norm = 0\n",
    "            non_zero_grads = 0\n",
    "            for p in self.parameters():\n",
    "                if p.grad is not None:\n",
    "                    grad_mean = p.grad.abs().mean()\n",
    "                    if grad_mean < 0.01:\n",
    "                        p.grad *= 2.0\n",
    "\n",
    "                    current_grad_norm += p.grad.norm().item()\n",
    "                    non_zero_grads += 1\n",
    "\n",
    "            avg_grad_norm = current_grad_norm / max(1, non_zero_grads)\n",
    "            dynamic_clip = min(clip, avg_grad_norm * 1.5)\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), dynamic_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total_grad_norm += current_grad_norm\n",
    "            batch_count += 1\n",
    "\n",
    "        return epoch_loss / len(dataloader)\n",
    "\n",
    "    def evaluate(self, dataloader, criterion):\n",
    "        self.eval()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, trg in dataloader:\n",
    "                src = src.to(self.device)\n",
    "                trg = trg.to(self.device)\n",
    "\n",
    "                output = self(src, trg, teacher_forcing_ratio=0.0)\n",
    "\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output[:, 1:].reshape(-1, output_dim)\n",
    "                trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "                loss = criterion(output, trg)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(dataloader)\n",
    "\n",
    "    def fit(self, train_loader, val_loader, optimizer, criterion, scheduler,\n",
    "            num_epochs=10, clip=1.0, early_stopping_patience=3, model_save_path='models/best_model_seq2seq.pt'):\n",
    "        \"\"\"Полный цикл обучения модели с ранним остановом\"\"\"\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_without_improvement = 0\n",
    "        previous_val_loss = None\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            start_time = time.time()\n",
    "            train_loss = self.train_epoch(train_loader, optimizer, criterion, clip)\n",
    "            val_loss = self.evaluate(val_loader, criterion)\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if previous_val_loss is not None and (abs(val_loss - previous_val_loss) <= 0.01 or val_loss > previous_val_loss):\n",
    "                epochs_without_improvement += 1\n",
    "            else:\n",
    "                epochs_without_improvement = 0\n",
    "\n",
    "            previous_val_loss = val_loss\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.state_dict(), model_save_path)\n",
    "\n",
    "            if epochs_without_improvement >= early_stopping_patience:\n",
    "                print(f\"Ранний останов после {epoch:02} эпох (val_loss изменяется менее чем на ±0.01 в течение {early_stopping_patience} эпох)!\")\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f\"{epochs_without_improvement}\\n\"\n",
    "                f\"Epoch {epoch:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} \"\n",
    "                f\"| LR: {optimizer.param_groups[0]['lr']:.6f} | Time: {epoch_time:.2f}s\"\n",
    "            )\n",
    "\n",
    "        self.load_state_dict(torch.load(model_save_path))\n",
    "        return best_val_loss\n",
    "\n",
    "    def generate_sequence(self, src_sequence, src_vocab, trg_vocab, max_len=20):\n",
    "        \"\"\"Генерация последовательности по входным данным\"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        if isinstance(src_sequence, str):\n",
    "            tokens = nltk.word_tokenize(src_sequence.lower())\n",
    "        else:\n",
    "            tokens = src_sequence\n",
    "\n",
    "        src_indexes = [src_vocab.word2index.get(token, src_vocab.word2index['<unk>']) for token in tokens]\n",
    "        print(src_indexes)\n",
    "        src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, (hidden, cell) = self.encoder(src_tensor)\n",
    "\n",
    "        trg_indexes = [trg_vocab.word2index['<sos>']]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output, hidden, cell = self.decoder(trg_tensor, hidden, cell)\n",
    "\n",
    "            pred_token = output.argmax(1).item()\n",
    "            trg_indexes.append(pred_token)\n",
    "\n",
    "            if pred_token == trg_vocab.word2index.get('<eos>', -1):\n",
    "                break\n",
    "\n",
    "        trg_tokens = []\n",
    "        for idx in trg_indexes[1:]:\n",
    "            token = trg_vocab.index2word.get(idx, \"<unk>\")\n",
    "            if token != \"eos\":\n",
    "                trg_tokens.append(token)\n",
    "\n",
    "        return trg_tokens\n",
    "\n",
    "    def calculate_bleu(self, dataloader, src_vocab, trg_vocab, max_len=20):\n",
    "        \"\"\"Вычисление BLEU score для DataLoader\"\"\"\n",
    "        self.eval()\n",
    "        references = []\n",
    "        hypotheses = []\n",
    "        smoothing = SmoothingFunction().method4\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, trg in dataloader:\n",
    "                src = src.to(self.device)\n",
    "                trg = trg.to(self.device)\n",
    "\n",
    "                output = self(src, trg, teacher_forcing_ratio=0.0)\n",
    "                output = output.argmax(dim=-1)\n",
    "\n",
    "                for i in range(trg.size(0)):\n",
    "                    ref_indices = trg[i].cpu().numpy()\n",
    "                    ref_tokens = []\n",
    "                    for idx in ref_indices:\n",
    "                        token = trg_vocab.index2word.get(int(idx), '<unk>')\n",
    "                        if token not in ['sos', 'eos', '<pad>']:\n",
    "                            ref_tokens.append(token)\n",
    "\n",
    "                    hyp_indices = output[i].cpu().numpy()\n",
    "                    hyp_tokens = []\n",
    "                    for idx in hyp_indices:\n",
    "                        token = trg_vocab.index2word.get(int(idx), '<unk>')\n",
    "                        if token == 'eos':\n",
    "                            break\n",
    "                        if token not in ['sos', '<pad>']:\n",
    "                            hyp_tokens.append(token)\n",
    "\n",
    "                    references.append([ref_tokens])\n",
    "                    hypotheses.append(hyp_tokens)\n",
    "\n",
    "        return corpus_bleu(references, hypotheses, smoothing_function=smoothing)\n",
    "\n"
   ],
   "id": "112642599d19c612",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "вайбкодинг",
   "id": "28ac6c37314af6ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:48.348293Z",
     "start_time": "2025-08-04T07:17:48.345616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAD_IDX = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ],
   "id": "9949ad8d773c9284",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:49.331614Z",
     "start_time": "2025-08-04T07:17:49.328064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 512\n",
    "EMB_DIM = 128\n",
    "ENC_DROPOUT = 0.4\n",
    "DEC_DROPOUT = 0.4\n",
    "N_LAYERS = 1"
   ],
   "id": "6c1a61a9ca2a86c4",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:50.433652Z",
     "start_time": "2025-08-04T07:17:50.302202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n"
   ],
   "id": "2f810147d4ff1457",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:52.068542Z",
     "start_time": "2025-08-04T07:17:52.066046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TitleDataset(train_pairs, input_vocab, target_vocab)\n",
    "val_dataset = TitleDataset(val_pairs, input_vocab, target_vocab)"
   ],
   "id": "95f34a5a8ce4a7f2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:53.762679Z",
     "start_time": "2025-08-04T07:17:53.758839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "31fc7d6ad82ad245",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:28:09.779631Z",
     "start_time": "2025-08-04T07:18:34.755161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AD_IDX = target_vocab.word2index[\"<pad>\"]\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.3,\n",
    "    patience=1,\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "best_val_loss = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=10,\n",
    "    clip=1.0,\n",
    "    early_stopping_patience=1,\n",
    "    model_save_path='../../models/best_model_seq2seq.pt'\n",
    ")"
   ],
   "id": "25f84db947334638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 01 | Train Loss: 4.657 | Val Loss: 4.416 | LR: 0.000300 | Time: 137.416s\n",
      "0\n",
      "Epoch 02 | Train Loss: 4.490 | Val Loss: 4.367 | LR: 0.000300 | Time: 143.363s\n",
      "0\n",
      "Epoch 03 | Train Loss: 4.423 | Val Loss: 4.319 | LR: 0.000300 | Time: 146.269s\n",
      "Ранний останов после 04 эпох (val_loss изменяется менее чем на ±0.01 в течение 1 эпох)!\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:44:07.338249Z",
     "start_time": "2025-08-04T07:44:07.336130Z"
    }
   },
   "cell_type": "code",
   "source": "model = Seq2Seq(encoder, decoder, device).to(device)",
   "id": "2a0b7edf1638dc7f",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:44:08.038662Z",
     "start_time": "2025-08-04T07:44:08.019236Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load(\"../../models/best_model_seq2seq.pt\"))",
   "id": "b766cb2ec0e7929b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:44:14.071517Z",
     "start_time": "2025-08-04T07:44:14.069466Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "4b5aac07e3b33aa0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderLSTM(\n",
       "    (embedding): Embedding(30000, 512)\n",
       "    (lstm): LSTM(512, 512, batch_first=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(1260, 128)\n",
       "    (rnn): LSTM(128, 512, dropout=0.4)\n",
       "    (fc_out): Linear(in_features=512, out_features=1260, bias=True)\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:43:14.431669Z",
     "start_time": "2025-08-04T07:43:14.418705Z"
    }
   },
   "cell_type": "code",
   "source": "model = torch.load('../../models/best_model_seq2seq.pt')",
   "id": "9aa994bc849b3ae9",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:43:40.360429Z",
     "start_time": "2025-08-04T07:43:40.355743Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "4ad280c986912f5d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.embedding.weight',\n",
       "              tensor([[ 0.9043,  1.2703,  0.7927,  ...,  0.9298,  0.4948, -0.9428],\n",
       "                      [-0.4735,  1.2940, -1.3461,  ..., -0.2412, -0.8427, -1.2836],\n",
       "                      [-0.4847, -0.5220,  0.0738,  ..., -1.3577,  1.1459, -1.8512],\n",
       "                      ...,\n",
       "                      [ 0.9665, -1.0452,  0.3203,  ...,  0.1029,  0.5494, -0.0333],\n",
       "                      [-0.7574,  1.0757,  0.3603,  ...,  1.0432,  1.2531,  1.6537],\n",
       "                      [-1.1803, -1.1679, -0.4149,  ..., -1.4314, -0.0824, -0.8447]])),\n",
       "             ('encoder.lstm.weight_ih_l0',\n",
       "              tensor([[-0.0067,  0.0259, -0.0045,  ..., -0.0115,  0.0413, -0.0193],\n",
       "                      [-0.0659,  0.0205, -0.0887,  ..., -0.0139, -0.0410, -0.0249],\n",
       "                      [-0.0602, -0.0203, -0.0176,  ...,  0.0026, -0.0741, -0.0297],\n",
       "                      ...,\n",
       "                      [ 0.0097,  0.0164,  0.0321,  ...,  0.0118,  0.0373,  0.0354],\n",
       "                      [-0.0331,  0.0028, -0.0217,  ...,  0.0299, -0.0362,  0.0208],\n",
       "                      [ 0.0380, -0.0139, -0.0189,  ..., -0.0083, -0.0510,  0.0258]])),\n",
       "             ('encoder.lstm.weight_hh_l0',\n",
       "              tensor([[ 0.0406, -0.0152,  0.0686,  ..., -0.0369,  0.0003, -0.0450],\n",
       "                      [ 0.0064, -0.0608,  0.0750,  ..., -0.0186, -0.0575, -0.0019],\n",
       "                      [-0.0336, -0.0302,  0.0156,  ..., -0.0242, -0.0384, -0.0160],\n",
       "                      ...,\n",
       "                      [ 0.0121, -0.0054,  0.0037,  ...,  0.0308,  0.0494, -0.0142],\n",
       "                      [-0.0361,  0.0625,  0.0236,  ...,  0.0348,  0.0194,  0.0553],\n",
       "                      [-0.0003, -0.0013, -0.0091,  ...,  0.0338, -0.0172,  0.0146]])),\n",
       "             ('encoder.lstm.bias_ih_l0',\n",
       "              tensor([ 0.0176,  0.0506, -0.0221,  ...,  0.0443, -0.0241, -0.0330])),\n",
       "             ('encoder.lstm.bias_hh_l0',\n",
       "              tensor([0.0419, 0.0365, 0.0508,  ..., 0.0016, 0.0008, 0.0198])),\n",
       "             ('decoder.embedding.weight',\n",
       "              tensor([[-0.0125, -0.6386, -1.0464,  ...,  0.8210,  0.0213,  1.6646],\n",
       "                      [ 0.9130, -2.0769, -0.3233,  ...,  0.3151, -0.5055,  1.4532],\n",
       "                      [ 1.7623, -3.0602,  1.6491,  ...,  0.8953,  0.2830,  0.5920],\n",
       "                      ...,\n",
       "                      [ 1.8030,  1.2623, -1.5314,  ...,  0.8833,  0.2591,  0.2791],\n",
       "                      [ 0.1638,  0.5183, -0.6859,  ...,  0.2420, -0.8649,  0.0159],\n",
       "                      [-1.7545,  0.5855, -0.7969,  ..., -0.5954,  0.7746, -0.8268]])),\n",
       "             ('decoder.rnn.weight_ih_l0',\n",
       "              tensor([[ 0.0288, -0.0232,  0.0184,  ...,  0.0215, -0.0107, -0.0026],\n",
       "                      [ 0.0645,  0.0144, -0.0235,  ..., -0.0382, -0.0257, -0.0129],\n",
       "                      [ 0.0426,  0.0177,  0.0063,  ...,  0.0547, -0.0272,  0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0019, -0.0295,  0.0075,  ...,  0.0393, -0.0526, -0.0274],\n",
       "                      [ 0.0370, -0.0062, -0.0317,  ..., -0.0420, -0.0124, -0.0277],\n",
       "                      [-0.0226,  0.0140, -0.0348,  ...,  0.0369, -0.0419, -0.0383]])),\n",
       "             ('decoder.rnn.weight_hh_l0',\n",
       "              tensor([[-0.0019,  0.0488,  0.0076,  ...,  0.0211,  0.0003,  0.0149],\n",
       "                      [-0.0361,  0.0506, -0.0132,  ..., -0.0103, -0.0140, -0.0450],\n",
       "                      [-0.0218,  0.0036, -0.0204,  ...,  0.0360,  0.0155,  0.0085],\n",
       "                      ...,\n",
       "                      [ 0.0313, -0.0132, -0.0451,  ..., -0.0006, -0.0250,  0.0014],\n",
       "                      [ 0.0092,  0.0129,  0.0118,  ...,  0.0283,  0.0130,  0.0017],\n",
       "                      [-0.0673, -0.0482,  0.0536,  ..., -0.0166, -0.0566,  0.0148]])),\n",
       "             ('decoder.rnn.bias_ih_l0',\n",
       "              tensor([-0.0144, -0.0171, -0.0269,  ..., -0.0243,  0.0401,  0.0447])),\n",
       "             ('decoder.rnn.bias_hh_l0',\n",
       "              tensor([ 0.0246,  0.0292,  0.0433,  ..., -0.0143,  0.0179,  0.0470])),\n",
       "             ('decoder.fc_out.weight',\n",
       "              tensor([[ 0.0158,  0.0232, -0.0239,  ...,  0.0498,  0.0161, -0.0080],\n",
       "                      [ 0.0732,  0.0089,  0.0457,  ..., -0.0536, -0.0640, -0.0097],\n",
       "                      [-0.0370,  0.0002,  0.0119,  ..., -0.0026,  0.0535,  0.0182],\n",
       "                      ...,\n",
       "                      [-0.0093, -0.0424,  0.0755,  ..., -0.0071,  0.0370,  0.0567],\n",
       "                      [-0.0003,  0.0145, -0.0130,  ...,  0.0169,  0.0188,  0.0265],\n",
       "                      [-0.0527,  0.0236, -0.0317,  ..., -0.0020,  0.0430,  0.0211]])),\n",
       "             ('decoder.fc_out.bias',\n",
       "              tensor([-0.0219, -0.0147,  0.0265,  ..., -0.0029,  0.0083,  0.0156]))])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:33:07.535801Z",
     "start_time": "2025-08-04T07:33:03.981763Z"
    }
   },
   "cell_type": "code",
   "source": "text = input()",
   "id": "a6cb2a7b2a6c4010",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:38:14.586571Z",
     "start_time": "2025-08-04T07:38:14.521917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.corpus import stopwords\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "stop_words = stopwords.words('russian')\n",
    "extra_stopwords = ['это', 'который', 'весь', 'свой', 'такой', 'тем', 'чтобы']\n",
    "stop_words.extend(extra_stopwords)\n",
    "stop_words = set(stop_words)"
   ],
   "id": "c8045dc9a7c4f765",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/veronika_steklo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/veronika_steklo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/veronika_steklo/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:38:17.254346Z",
     "start_time": "2025-08-04T07:38:17.250491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def normalize_word(word: str) -> str:\n",
    "    return morph.parse(word)[0].normal_form.replace('ё', 'е')\n",
    "\n",
    "def normalization(text: List[str]) -> List[str]:\n",
    "    return [normalize_word(word) for word in text]"
   ],
   "id": "d64667d0f25dea38",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:39:20.693298Z",
     "start_time": "2025-08-04T07:39:20.689961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = normalization(tokens)\n",
    "    return [token for token in tokens if token not in stop_words]\n"
   ],
   "id": "eda98c95abf11508",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:39:21.856543Z",
     "start_time": "2025-08-04T07:39:21.852044Z"
    }
   },
   "cell_type": "code",
   "source": "text",
   "id": "ed2673b3c7b162eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'— На днях в Лондоне, — продолжал он, — молодая девушка села в кэб. Она ехала встречать мать, с которой не виделась много лет. На углу какой-то улицы оглобля повозки разбивает в мелкие осколки окна кэба, длинный, как игла, осколок разбитого стекла пронзает сердце девушки. Она тут же умирает. Репортер называет это трагической смертью. Это неверно. Это не соответствует моим определениям сострадания и страха.\\nЧувство трагического, по сути дела, — это лицо, обращенное в обе стороны, к страху и к состраданию, каждая из которых — его фаза. Ты заметил, я употребил слово «останавливает». Тем самым я подчеркиваю, что трагическая эмоция статична. Вернее, драматическая эмоция. Чувства, возбуждаемые неподлинным искусством, кинетичны: это влечение и отвращение. Влечение побуждает нас приблизиться, овладеть. Отвращение побуждает покинуть, отвергнуть. Искусства, вызывающие эти чувства, — порнография и дидактика — неподлинные искусства. Таким образом, эстетическое чувство статично. Мысль останавливается и парит над влечением и отвращением.\\n— Ты говоришь, что искусство не должно возбуждать влечения, — сказал Линч. — Помню, я однажды тебе рассказывал, что в музее написал карандашом свое имя на заднице Венеры Праксителя. Разве это не влечение?\\n— Я имею в виду нормальные натуры, — сказал Стивен. — Ты еще рассказывал мне, как ел коровий навоз в своей распрекрасной кармелитской школе.\\nЛинч снова заржал и потер в паху руку об руку, не вынимая их из карманов.\\n— Да, было такое дело! — воскликнул он.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:39:23.405794Z",
     "start_time": "2025-08-04T07:39:23.390766Z"
    }
   },
   "cell_type": "code",
   "source": "print(normalize_text(text))",
   "id": "4eaf449e95e17a60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['день', 'лондон', 'продолжать', 'молодой', 'девушка', 'село', 'кэб', 'ехать', 'встречать', 'мать', 'видеться', 'год', 'угол', 'какойтый', 'улица', 'оглобля', 'повозка', 'разбивать', 'мелкий', 'осколок', 'окно', 'кэб', 'длинный', 'игла', 'осколок', 'разбитый', 'стекло', 'пронзать', 'сердце', 'девушка', 'умирать', 'репортер', 'называть', 'трагический', 'смерть', 'неверно', 'соответствовать', 'определение', 'сострадание', 'страх', 'чувство', 'трагический', 'суть', 'дело', 'лицо', 'обратить', 'оба', 'сторона', 'страх', 'сострадание', 'каждый', 'фаза', 'заметить', 'употребить', 'слово', 'останавливать', 'самый', 'подчеркивать', 'трагический', 'эмоция', 'статичный', 'верный', 'драматический', 'эмоция', 'чувство', 'возбуждать', 'неподлинный', 'искусство', 'кинетичный', 'влечение', 'отвращение', 'влечение', 'побуждать', 'приблизиться', 'овладеть', 'отвращение', 'побуждать', 'покинуть', 'отвергнуть', 'искусство', 'вызывающий', 'чувство', 'порнография', 'дидактик', 'неподлинный', 'искусство', 'образ', 'эстетический', 'чувство', 'статично', 'мысль', 'останавливаться', 'парить', 'влечение', 'отвращение', 'говорить', 'искусство', 'должный', 'возбуждать', 'влечение', 'сказать', 'линч', 'помнить', 'однажды', 'рассказывать', 'музей', 'написать', 'карандаш', 'имя', 'задница', 'венера', 'праксителя', 'влечение', 'иметь', 'вид', 'нормальный', 'натура', 'сказать', 'стивен', 'рассказывать', 'коровий', 'навоз', 'распрекрасный', 'кармелитский', 'школа', 'линч', 'снова', 'заржать', 'потереть', 'пах', 'рука', 'рука', 'вынимать', 'карман', 'дело', 'воскликнуть']\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:43:24.122660Z",
     "start_time": "2025-08-04T07:43:24.098570Z"
    }
   },
   "cell_type": "code",
   "source": "model.generate_sequence(normalize_text(text), src_vocab=input_vocab, trg_vocab=target_vocab)",
   "id": "53e9070751f0e439",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'generate_sequence'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[47]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgenerate_sequence\u001B[49m(normalize_text(text), src_vocab=input_vocab, trg_vocab=target_vocab)\n",
      "\u001B[31mAttributeError\u001B[39m: 'collections.OrderedDict' object has no attribute 'generate_sequence'"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:28:28.470820Z",
     "start_time": "2025-08-04T07:28:23.598467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bleu_score = model.calculate_bleu(val_loader, input_vocab, target_vocab)\n",
    "print(f'Validation BLEU score: {bleu_score*100:.2f}')"
   ],
   "id": "a420e51184df6012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation BLEU score: 4.37\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:29:34.731055Z",
     "start_time": "2025-08-04T07:29:34.724148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_title(model, input_text, input_vocab, target_vocab, max_len=50, device=\"cpu\", temperature=0.7):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = re.findall(r\"\\w+|[.,!?;]\", input_text.lower())\n",
    "    src_indexes = [input_vocab.word2index.get(token, input_vocab.word2index[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "    if not src_indexes:\n",
    "        return \"Невозможно проанализировать текст\"\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = [target_vocab.word2index[\"<sos>\"]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "\n",
    "        output_dist = output[0,-1].div(temperature).exp()\n",
    "        pred_token = torch.multinomial(output_dist, 1).item()\n",
    "\n",
    "        if pred_token == target_vocab.word2index[\"<eos>\"] or (i > 10 and len(set(trg_indexes[-5:])) < 2):\n",
    "            break\n",
    "\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "    filtered = []\n",
    "    for idx in trg_indexes[1:]:\n",
    "        word = target_vocab.index_to_word(idx)\n",
    "        if word not in [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"] and not word.isdigit():\n",
    "            filtered.append(word)\n",
    "\n",
    "    result = ' '.join(filtered).capitalize()\n",
    "    result = re.sub(r'\\s([?.!,](?:\\s|$))', r'\\1', result)\n",
    "\n",
    "    return result"
   ],
   "id": "2c9bbed6485fa289",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:30:57.642111Z",
     "start_time": "2025-08-04T07:29:37.256263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "\n",
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=0.4)\n",
    "decoder = Decoder(OUTPUT_DIM, 128, HID_DIM, N_LAYERS, 0.4)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model.load_state_dict(torch.load('../../models/best_model_seq2seq.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Генератор названий\")\n",
    "print(\"Введите текст (или 'выход' для завершения):\")\n",
    "\n",
    "while True:\n",
    "    input_text = input(\"\\n> \")\n",
    "\n",
    "    if input_text.lower() in ['выход', 'exit', 'quit']:\n",
    "        break\n",
    "\n",
    "    if len(input_text.strip()) == 0:\n",
    "        print(\"Пожалуйста, введите текст.\")\n",
    "        continue\n",
    "\n",
    "    title = generate_title(model, input_text, input_vocab, target_vocab, device=device)\n",
    "    print(\"\\nСгенерированное название:\")\n",
    "    print(title)\n",
    "    print(\"\\nВведите следующий текст или 'выход' для завершения:\")\n"
   ],
   "id": "d1a2b381fdee660",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генератор названий\n",
      "Введите текст (или 'выход' для завершения):\n",
      "\n",
      "Сгенерированное название:\n",
      "Очень\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Город\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Цивилизация.\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Филип\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Мало\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Рай\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Знать.\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Дух в\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Сказка за\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Уже\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Какой\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Красота король\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Серый\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Владимир\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Возвращение\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "Пожалуйста, введите текст.\n",
      "\n",
      "Сгенерированное название:\n",
      "Духовный седьмой\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Эссе корнеслов\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Еврей на\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "Пожалуйста, введите текст.\n",
      "\n",
      "Сгенерированное название:\n",
      "Отбор\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Календарь\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[25]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mВведите текст (или \u001B[39m\u001B[33m'\u001B[39m\u001B[33mвыход\u001B[39m\u001B[33m'\u001B[39m\u001B[33m для завершения):\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     input_text = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43m> \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m input_text.lower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mвыход\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mexit\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mquit\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     20\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1280\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1281\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1283\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1284\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1285\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1287\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1322\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1323\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1324\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1325\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1326\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1327\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-04T07:17:25.538461Z",
     "start_time": "2025-08-04T07:17:25.534236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Размер словаря:\", len(target_vocab))\n",
    "print(\"Примеры слов:\", [target_vocab.index_to_word(i) for i in range(10)])"
   ],
   "id": "d2b60dc46e62cbfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 1260\n",
      "Примеры слов: ['<pad>', '<unk>', '<sos>', '<eos>', '.', ',', '...', 'и', 'в', '!']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:24:13.559333Z",
     "start_time": "2025-07-31T07:57:23.667546Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "32eacf46ad395f63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
