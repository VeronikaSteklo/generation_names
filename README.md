# Генерация и оценка названий рассказов с использованием NLP

Проект посвящён исследованию и сравнению различных архитектур для генерации 
названий художественных текстов на основе их содержания.

### Цель проекта:
Разработать и сравнить модели, способные генерировать осмысленные и 
стилистически подходящие названия для коротких литературных текстов (рассказов и аннотаций).

Проект рассматривает задачу text $\to$ title generation как:
- задачу условной генерации текста; 
- исследование влияния архитектуры модели на качество генерации; 
- эволюцию подходов — от простых статистических моделей к трансформерам.

### В качестве датасета используются пары (текст, название), собранные из открытых литературных источников:
1. художественные рассказы и их названия (Проза.ру, ЛитПричал); 
2. аннотации к классической литературе (ЛитРес);
3. краткие пересказы произведений (Briefly). 

### Подготовка данных:
1. реализован парсинг нескольких литературных сайтов; 
2. тексты приведены к единому формату; 
3. тексты разбиты на фрагменты по 2–3 предложения для упрощения задачи генерации;

### Реализованные модели:
#### 1. N-граммная модель

Реализована в качестве отправной точки и исторического базиса.
- статистический подход к генерации текста; 
- позволяет продемонстрировать ограничения локального контекста; 
- используется как baseline для сравнения с нейросетевыми моделями.

#### 2. Seq2Seq (Encoder–Decoder)
- классическая архитектура для задач генерации текста; 
- используется рекуррентная нейронная сеть; 
- модель реализована и протестирована, однако демонстрирует нестабильные результаты, что послужило дополнительной мотивацией для перехода к трансформерам;

#### 3. Transformer (Attention Is All You Need)
- реализация архитектуры трансформера на основе оригинальной статьи
“Attention Is All You Need”;
- обучение модели для генерации названий по входному тексту;
- по результатам экспериментов сделан вывод, что объёма и разнообразия текущего датасета недостаточно для эффективного обучения трансформера «с нуля» в задаче генерации названий;  
- трансформер рассматривается как ключевое направление развития проекта, однако дальнейшая работа планируется в сторону использования предобученных языковых моделей и fine-tuning, что более соответствует природе задачи и объёму доступных данных.
