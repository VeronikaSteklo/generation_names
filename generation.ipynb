{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:34.324186Z",
     "start_time": "2025-07-31T09:15:34.321496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from openai import models\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
    "import nltk\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "bbb7bed3664fb591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:34.339351Z",
     "start_time": "2025-07-31T09:15:34.336478Z"
    }
   },
   "cell_type": "code",
   "source": "nltk.download('punkt')",
   "id": "500983476805736",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/veronika_steklo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:37.913775Z",
     "start_time": "2025-07-31T09:15:34.345564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('data/data_tokenize.csv')\n",
    "pairs = list(dataset[[\"title\", \"text\"]].itertuples(index=False, name=None))\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)"
   ],
   "id": "d32ab7766f117c02",
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:37.923356Z",
     "start_time": "2025-07-31T09:15:37.921803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sos_token = 0\n",
    "eos_token = 1\n",
    "MAX_VOCAB_SIZE = 30_000\n",
    "\n",
    "MAX_INPUT_LEN = 300\n",
    "MAX_TARGET_LEN = 30\n"
   ],
   "id": "494f3908570a88c1",
   "outputs": [],
   "execution_count": 136
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Работа с данными",
   "id": "b19158c090ab7cd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Словарь частот",
   "id": "fc6eb2179a03ea77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:37.929798Z",
     "start_time": "2025-07-31T09:15:37.926331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    \"\"\"Создаёт словари с частотами слов на основе входных данных\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<pad>\": 0, \"<unk>\": 1, \"<sos>\": 2, \"<eos>\": 3}\n",
    "        self.word2count = {\"<pad>\": 0, \"<unk>\": 0, \"<sos>\": 0, \"<eos>\": 0}\n",
    "        self.index2word = {0: \"<pad>\", 1: \"<unk>\", 2: \"<sos>\", 3: \"<eos>\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "        self._temp_word_counts = {}\n",
    "\n",
    "    def addText(self, text: str):\n",
    "        \"\"\"Для каждого слова в тексте добавляет его во временный счётчик\"\"\"\n",
    "        for word in text.split():\n",
    "            self._temp_word_counts[word] = self._temp_word_counts.get(word, 0) + 1\n",
    "\n",
    "    def build_vocab(self, is_text: bool = False):\n",
    "        \"\"\"Строит финальный словарь после подсчёта всех слов\"\"\"\n",
    "        sorted_words = sorted(self._temp_word_counts.items(),\n",
    "                            key=lambda x: x[1],\n",
    "                            reverse=True)\n",
    "\n",
    "        for word, count in sorted_words[:MAX_VOCAB_SIZE - 4]:\n",
    "            if word not in self.word2index:\n",
    "\n",
    "                if is_text:\n",
    "                    if count > 10:\n",
    "                        self.word2index[word] = self.n_words\n",
    "                        self.word2count[word] = count\n",
    "                        self.index2word[self.n_words] = word\n",
    "                        self.n_words += 1\n",
    "                    else:\n",
    "                        self.word2count[\"<unk>\"] += count\n",
    "\n",
    "                else:\n",
    "                    if count > 5:\n",
    "                        self.word2index[word] = self.n_words\n",
    "                        self.word2count[word] = count\n",
    "                        self.index2word[self.n_words] = word\n",
    "                        self.n_words += 1\n",
    "                    else:\n",
    "                        self.word2count[\"<unk>\"] += count\n",
    "\n",
    "        for word, count in sorted_words[MAX_VOCAB_SIZE - 4:]:\n",
    "            self.word2count[\"<unk>\"] += count\n",
    "\n",
    "    def word_to_index(self, word: str) -> int:\n",
    "        \"\"\"Возвращает индекс слова или <unk>\"\"\"\n",
    "        return self.word2index.get(word, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def index_to_word(self, index: int) -> str:\n",
    "        \"\"\"Возвращает слово по индексу\"\"\"\n",
    "        return self.index2word.get(index, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Строковое представление словаря\"\"\"\n",
    "        return (\n",
    "            f\"Vocab(name='{self.name}', \"\n",
    "            f\"n_words={self.n_words}, \"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2index)"
   ],
   "id": "af697d8019de7b60",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:37.948027Z",
     "start_time": "2025-07-31T09:15:37.932228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_vocab = Vocab(\"title\")\n",
    "text_vocab = Vocab(\"text\")"
   ],
   "id": "b7bab9bf9cf85f0f",
   "outputs": [],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:43.110513Z",
     "start_time": "2025-07-31T09:15:37.950812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for text in dataset['text']:\n",
    "    text_vocab.addText(text)\n",
    "\n",
    "for title in dataset['title']:\n",
    "    title_vocab.addText(title)\n",
    "\n",
    "text_vocab.build_vocab()\n",
    "title_vocab.build_vocab()"
   ],
   "id": "852c28e87423675e",
   "outputs": [],
   "execution_count": 139
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:43.121237Z",
     "start_time": "2025-07-31T09:15:43.119135Z"
    }
   },
   "cell_type": "code",
   "source": "text_vocab.__str__(), title_vocab.__str__()",
   "id": "744bafb50cbed8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Vocab(name='text', n_words=30000, \", \"Vocab(name='title', n_words=1205, \")"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.568956Z",
     "start_time": "2025-07-31T09:15:43.127499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = Vocab(\"input\")\n",
    "target_vocab = Vocab(\"target\")\n",
    "\n",
    "for title, text in train_pairs:\n",
    "    input_vocab.addText(text)\n",
    "    target_vocab.addText(title)\n",
    "\n",
    "input_vocab.build_vocab(is_text=True)\n",
    "target_vocab.build_vocab(is_text=False)\n"
   ],
   "id": "9bd4598240aaaf2",
   "outputs": [],
   "execution_count": 141
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Преобразование текста в датасет",
   "id": "30166912bd00d08f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.577595Z",
     "start_time": "2025-07-31T09:15:47.575794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_tensor(text: str, vocab: Vocab, add_sos_eos=True, max_len: int | None = None, truncate_from_start=False) -> torch.Tensor:\n",
    "    \"\"\"Преобразует текст в тензоры, с опциональной обрезкой\"\"\"\n",
    "    tokens = text.strip().split()\n",
    "\n",
    "    if max_len is not None:\n",
    "        if truncate_from_start:\n",
    "            tokens = tokens[-max_len:]\n",
    "        else:\n",
    "            tokens = tokens[:max_len]\n",
    "\n",
    "    indices = [vocab.word_to_index(w) for w in tokens]\n",
    "\n",
    "    if add_sos_eos:\n",
    "        indices = [vocab.word2index[\"<sos>\"]] + indices + [vocab.word2index[\"<eos>\"]]\n",
    "\n",
    "    return torch.tensor(indices, dtype=torch.long)\n"
   ],
   "id": "97e9048e47fad56b",
   "outputs": [],
   "execution_count": 142
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.581674Z",
     "start_time": "2025-07-31T09:15:47.579760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, pairs: list[tuple[str, str]], input_vocab: Vocab, output_vocab: Vocab):\n",
    "        \"\"\"\n",
    "            pairs — список пар (название, текст),\n",
    "            input_vocab - словарь с частотами слов из текстов,\n",
    "            output_vocab - словарь с частотами слов из названий\n",
    "        \"\"\"\n",
    "        self.pairs = pairs\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title, text = self.pairs[idx]\n",
    "        input_tensor = text_to_tensor(text, self.input_vocab, add_sos_eos=False, max_len=300)\n",
    "        target_tensor = text_to_tensor(title, self.output_vocab, add_sos_eos=False, max_len=30)\n",
    "        return input_tensor, target_tensor\n"
   ],
   "id": "cd131f5993493712",
   "outputs": [],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.585232Z",
     "start_time": "2025-07-31T09:15:47.583763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch: List[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    batch: list of (input_tensor, target_tensor)\n",
    "    Returns:\n",
    "        input_padded: [batch, src_len]\n",
    "        target_padded: [batch, trg_len]\n",
    "    \"\"\"\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_padded = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "\n",
    "    return src_padded, trg_padded\n"
   ],
   "id": "69762e8b16737afb",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Модель seq2seq",
   "id": "789cf67de81efcf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Энкодер для seq2seq",
   "id": "721ebb0bf826a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.588920Z",
     "start_time": "2025-07-31T09:15:47.587155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.3):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ],
   "id": "876bda39f0cca67d",
   "outputs": [],
   "execution_count": 145
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Декодер для seq2seq",
   "id": "675fe048e3c70629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.592801Z",
     "start_time": "2025-07-31T09:15:47.590883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ],
   "id": "a16bdbd14838a2c0",
   "outputs": [],
   "execution_count": 146
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Модель",
   "id": "a48522022988539d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:37:13.261934Z",
     "start_time": "2025-07-31T09:37:13.052658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hid_dim, \"Hidden dimensions must match!\"\n",
    "        assert decoder.n_layers == 1, \"Encoder must produce compatible layers for decoder\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.1):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # [batch_size, trg_len, vocab_size]\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def train_epoch(self, dataloader, optimizer, criterion, clip=1.0):\n",
    "        self.train()\n",
    "        epoch_loss = 0\n",
    "        total_grad_norm = 0\n",
    "        batch_count = 0\n",
    "\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(self.device)\n",
    "            trg = trg.to(self.device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = self(src, trg)\n",
    "            output_dim = outputs.shape[-1]\n",
    "            outputs = outputs[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, trg)\n",
    "            loss.backward()\n",
    "\n",
    "            current_grad_norm = 0\n",
    "            non_zero_grads = 0\n",
    "            for p in self.parameters():\n",
    "                if p.grad is not None:\n",
    "                    grad_mean = p.grad.abs().mean()\n",
    "                    if grad_mean < 0.01:\n",
    "                        p.grad *= 2.0\n",
    "\n",
    "                    current_grad_norm += p.grad.norm().item()\n",
    "                    non_zero_grads += 1\n",
    "\n",
    "            avg_grad_norm = current_grad_norm / max(1, non_zero_grads)\n",
    "            dynamic_clip = min(clip, avg_grad_norm * 1.5)\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(self.parameters(), dynamic_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            total_grad_norm += current_grad_norm\n",
    "            batch_count += 1\n",
    "\n",
    "        return epoch_loss / len(dataloader)\n",
    "\n",
    "    def evaluate(self, dataloader, criterion):\n",
    "        self.eval()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, trg in dataloader:\n",
    "                src = src.to(self.device)\n",
    "                trg = trg.to(self.device)\n",
    "\n",
    "                output = self(src, trg, teacher_forcing_ratio=0.0)\n",
    "\n",
    "                output_dim = output.shape[-1]\n",
    "                output = output[:, 1:].reshape(-1, output_dim)\n",
    "                trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "                loss = criterion(output, trg)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        return epoch_loss / len(dataloader)\n",
    "\n",
    "    def fit(self, train_loader, val_loader, optimizer, criterion, scheduler,\n",
    "            num_epochs=10, clip=1.0, early_stopping_patience=3, model_save_path='models/best_model.pt'):\n",
    "        \"\"\"Полный цикл обучения модели с ранним остановом\"\"\"\n",
    "        best_val_loss = float('inf')\n",
    "        epochs_without_improvement = 0\n",
    "        previous_val_loss = None\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            start_time = time.time()\n",
    "            train_loss = self.train_epoch(train_loader, optimizer, criterion, clip)\n",
    "            val_loss = self.evaluate(val_loader, criterion)\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "            if previous_val_loss is not None and (abs(val_loss - previous_val_loss) <= 0.01 or val_loss > previous_val_loss):\n",
    "                epochs_without_improvement += 1\n",
    "            else:\n",
    "                epochs_without_improvement = 0\n",
    "\n",
    "            previous_val_loss = val_loss\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                torch.save(self.state_dict(), model_save_path)\n",
    "\n",
    "            if epochs_without_improvement >= early_stopping_patience:\n",
    "                print(f\"Ранний останов после {epoch:02} эпох (val_loss изменяется менее чем на ±0.01 в течение {early_stopping_patience} эпох)!\")\n",
    "                break\n",
    "\n",
    "            print(\n",
    "                f\"{epochs_without_improvement}\\n\"\n",
    "                f\"Epoch {epoch:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} \"\n",
    "                f\"| LR: {optimizer.param_groups[0]['lr']:.6f} | Time: {epoch_time:.3f}s\"\n",
    "            )\n",
    "\n",
    "        self.load_state_dict(torch.load(model_save_path))\n",
    "        return best_val_loss\n",
    "\n",
    "    def generate_sequence(self, src_sequence, src_vocab, trg_vocab, max_len=20):\n",
    "        \"\"\"Генерация последовательности по входным данным\"\"\"\n",
    "        self.eval()\n",
    "\n",
    "        # Добавляем служебные токены (если используете)\n",
    "        if isinstance(src_sequence, str):\n",
    "            tokens = nltk.word_tokenize(src_sequence.lower())\n",
    "        else:\n",
    "            tokens = src_sequence\n",
    "\n",
    "        # Преобразуем в индексы\n",
    "        src_indexes = [src_vocab.word2index.get(token, src_vocab.word2index['<unk>']) for token in tokens]\n",
    "        src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs, (hidden, cell) = self.encoder(src_tensor)\n",
    "\n",
    "        # Начинаем с начального токена\n",
    "        trg_indexes = [trg_vocab.word2index['<sos>']]\n",
    "\n",
    "        for _ in range(max_len):\n",
    "            trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output, hidden, cell = self.decoder(trg_tensor, hidden, cell)\n",
    "\n",
    "            pred_token = output.argmax(1).item()\n",
    "            trg_indexes.append(pred_token)\n",
    "\n",
    "            if pred_token == trg_vocab.word2index.get('<eos>', -1):\n",
    "                break\n",
    "\n",
    "        # Преобразуем индексы обратно в слова\n",
    "        trg_tokens = []\n",
    "        for idx in trg_indexes[1:]:  # пропускаем <sos>\n",
    "            token = trg_vocab.index2word.get(idx, \"<unk>\")\n",
    "            if token != \"eos\":\n",
    "                trg_tokens.append(token)\n",
    "\n",
    "        return trg_tokens\n",
    "\n",
    "    def calculate_bleu(self, dataloader, src_vocab, trg_vocab, max_len=20):\n",
    "        \"\"\"Вычисление BLEU score для DataLoader\"\"\"\n",
    "        self.eval()\n",
    "        references = []\n",
    "        hypotheses = []\n",
    "        smoothing = SmoothingFunction().method4\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for src, trg in dataloader:\n",
    "                src = src.to(self.device)\n",
    "                trg = trg.to(self.device)\n",
    "\n",
    "                # Генерируем предсказания для всего батча\n",
    "                output = self(src, trg, teacher_forcing_ratio=0.0)\n",
    "                output = output.argmax(dim=-1)\n",
    "\n",
    "                # Обрабатываем каждый пример в батче\n",
    "                for i in range(trg.size(0)):\n",
    "                    # Эталонная последовательность (исключаем служебные токены)\n",
    "                    ref_indices = trg[i].cpu().numpy()  # Конвертируем в numpy array\n",
    "                    ref_tokens = []\n",
    "                    for idx in ref_indices:\n",
    "                        token = trg_vocab.index2word.get(int(idx), '<unk>')\n",
    "                        if token not in ['sos', 'eos', '<pad>']:\n",
    "                            ref_tokens.append(token)\n",
    "\n",
    "                    # Предсказанная последовательность\n",
    "                    hyp_indices = output[i].cpu().numpy()\n",
    "                    hyp_tokens = []\n",
    "                    for idx in hyp_indices:\n",
    "                        token = trg_vocab.index2word.get(int(idx), '<unk>')\n",
    "                        if token == 'eos':\n",
    "                            break\n",
    "                        if token not in ['sos', '<pad>']:\n",
    "                            hyp_tokens.append(token)\n",
    "\n",
    "                    references.append([ref_tokens])\n",
    "                    hypotheses.append(hyp_tokens)\n",
    "\n",
    "        return corpus_bleu(references, hypotheses, smoothing_function=smoothing)\n",
    "\n"
   ],
   "id": "112642599d19c612",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "вайбкодинг",
   "id": "28ac6c37314af6ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.604667Z",
     "start_time": "2025-07-31T09:15:47.603443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAD_IDX = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ],
   "id": "9949ad8d773c9284",
   "outputs": [],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.607915Z",
     "start_time": "2025-07-31T09:15:47.606602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 512\n",
    "EMB_DIM = 128\n",
    "ENC_DROPOUT = 0.4\n",
    "DEC_DROPOUT = 0.4\n",
    "N_LAYERS = 1"
   ],
   "id": "6c1a61a9ca2a86c4",
   "outputs": [],
   "execution_count": 149
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:37:25.859755Z",
     "start_time": "2025-07-31T09:37:25.729630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n"
   ],
   "id": "2f810147d4ff1457",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.730695Z",
     "start_time": "2025-07-31T09:15:47.728902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TitleDataset(train_pairs, input_vocab, target_vocab)\n",
    "val_dataset = TitleDataset(val_pairs, input_vocab, target_vocab)"
   ],
   "id": "95f34a5a8ce4a7f2",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:15:47.768078Z",
     "start_time": "2025-07-31T09:15:47.735197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "31fc7d6ad82ad245",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:24:13.454243Z",
     "start_time": "2025-07-31T09:15:47.772510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AD_IDX = target_vocab.word2index[\"<pad>\"]\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.3,\n",
    "    patience=1,\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "best_val_loss = model.fit(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=10,\n",
    "    clip=1.0,\n",
    "    early_stopping_patience=1,\n",
    "    model_save_path='models/best_model.pt'\n",
    ")"
   ],
   "id": "25f84db947334638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 01 | Train Loss: 4.103 | Val Loss: 3.861 | LR: 0.000300 | Time: 127.593s\n",
      "0\n",
      "Epoch 02 | Train Loss: 3.932 | Val Loss: 3.798 | LR: 0.000300 | Time: 125.631s\n",
      "0\n",
      "Epoch 03 | Train Loss: 3.856 | Val Loss: 3.750 | LR: 0.000300 | Time: 125.824s\n",
      "Ранний останов после 04 эпох (val_loss изменяется менее чем на ±0.01 в течение 1 эпох)!\n"
     ]
    }
   ],
   "execution_count": 153
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:37:29.345183Z",
     "start_time": "2025-07-31T09:37:29.306305Z"
    }
   },
   "cell_type": "code",
   "source": "model.load_state_dict(torch.load(\"models/best_model.pt\"))",
   "id": "b766cb2ec0e7929b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:37:34.637658Z",
     "start_time": "2025-07-31T09:37:29.961537Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bleu_score = model.calculate_bleu(val_loader, input_vocab, target_vocab)\n",
    "print(f'Validation BLEU score: {bleu_score*100:.2f}')"
   ],
   "id": "a420e51184df6012",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation BLEU score: 6.41\n"
     ]
    }
   ],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:24:13.558774Z",
     "start_time": "2025-07-31T07:55:24.235276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_title(model, input_text, input_vocab, target_vocab, max_len=50, device=\"cpu\", temperature=0.7):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = re.findall(r\"\\w+|[.,!?;]\", input_text.lower())\n",
    "    src_indexes = [input_vocab.word2index.get(token, input_vocab.word2index[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "    if not src_indexes:\n",
    "        return \"Невозможно проанализировать текст\"\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = [target_vocab.word2index[\"<sos>\"]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "\n",
    "        output_dist = output[0,-1].div(temperature).exp()\n",
    "        pred_token = torch.multinomial(output_dist, 1).item()\n",
    "\n",
    "        if pred_token == target_vocab.word2index[\"<eos>\"] or (i > 10 and len(set(trg_indexes[-5:])) < 2):\n",
    "            break\n",
    "\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "    filtered = []\n",
    "    for idx in trg_indexes[1:]:\n",
    "        word = target_vocab.index_to_word(idx)\n",
    "        if word not in [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"] and not word.isdigit():\n",
    "            filtered.append(word)\n",
    "\n",
    "    result = ' '.join(filtered).capitalize()\n",
    "    result = re.sub(r'\\s([?.!,](?:\\s|$))', r'\\1', result)\n",
    "\n",
    "    return result"
   ],
   "id": "2c9bbed6485fa289",
   "outputs": [],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:24:13.558998Z",
     "start_time": "2025-07-31T07:55:24.244557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "\n",
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=0.4)\n",
    "decoder = Decoder(OUTPUT_DIM, 128, HID_DIM, N_LAYERS, 0.4)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model.load_state_dict(torch.load('models/best_model.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Генератор названий\")\n",
    "print(\"Введите текст (или 'выход' для завершения):\")\n",
    "\n",
    "while True:\n",
    "    input_text = input(\"\\n> \")\n",
    "\n",
    "    if input_text.lower() in ['выход', 'exit', 'quit']:\n",
    "        break\n",
    "\n",
    "    if len(input_text.strip()) == 0:\n",
    "        print(\"Пожалуйста, введите текст.\")\n",
    "        continue\n",
    "\n",
    "    title = generate_title(model, input_text, input_vocab, target_vocab, device=device)\n",
    "    print(\"\\nСгенерированное название:\")\n",
    "    print(title)\n",
    "    print(\"\\nВведите следующий текст или 'выход' для завершения:\")\n"
   ],
   "id": "d1a2b381fdee660",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генератор названий\n",
      "Введите текст (или 'выход' для завершения):\n",
      "\n",
      "Сгенерированное название:\n",
      "Они 1.\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Стал ответ.\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Анна.\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Искусство и\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Поколения самый i.\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Роза\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированное название:\n",
      "Диалоги слово ...\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:24:13.559228Z",
     "start_time": "2025-07-31T07:57:23.656631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Размер словаря:\", len(target_vocab))\n",
    "print(\"Примеры слов:\", [target_vocab.index_to_word(i) for i in range(10)])"
   ],
   "id": "d2b60dc46e62cbfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 1090\n",
      "Примеры слов: ['<pad>', '<unk>', 'sos', 'eos', '<sos>', '<eos>', '.', ',', '...', 'и']\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T09:24:13.559333Z",
     "start_time": "2025-07-31T07:57:23.667546Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "32eacf46ad395f63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
