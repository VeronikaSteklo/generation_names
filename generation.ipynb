{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:08.790555Z",
     "start_time": "2025-07-25T08:51:08.785496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "bbb7bed3664fb591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:12.513280Z",
     "start_time": "2025-07-25T08:51:08.798848Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = pd.read_csv('data/data_tokenize.csv')",
   "id": "d32ab7766f117c02",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:12.524282Z",
     "start_time": "2025-07-25T08:51:12.522993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ],
   "id": "494f3908570a88c1",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:12.528411Z",
     "start_time": "2025-07-25T08:51:12.526278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_VOCAB_SIZE = 100_000  # Оставляем только 100к самых частых слов\n",
    "\n",
    "class Vocab:\n",
    "    \"\"\"Создаёт словари на основе входных данных\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<UNK>\": 0, \"SOS\": 1, \"EOS\": 2}\n",
    "        self.word2count = {\"<UNK>\": 0}\n",
    "        self.index2word = {0: \"<UNK>\", 1: \"SOS\", 2: \"EOS\"}\n",
    "        self.n_words = 3\n",
    "\n",
    "    def addText(self, text: str):\n",
    "        \"\"\"Для каждого слова в тексте добавляет его в словарь\"\"\"\n",
    "        for word in text.split():\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        \"\"\"Добавляет слова в словари\"\"\"\n",
    "        if word not in self.word2index:\n",
    "            if self.n_words < MAX_VOCAB_SIZE:  # Лимит на размер словаря\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.word2count[word] = 1\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "            else:\n",
    "                self.word2count[\"<UNK>\"] += 1  # Редкие слова -> <UNK>\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Строковое представление словаря\"\"\"\n",
    "        return (\n",
    "            f\"Vocab(name='{self.name}', \"\n",
    "            f\"n_words={self.n_words}, \"\n",
    "        )"
   ],
   "id": "af697d8019de7b60",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:12.534622Z",
     "start_time": "2025-07-25T08:51:12.533219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_vocab = Vocab(\"title\")\n",
    "text_vocab = Vocab(\"text\")"
   ],
   "id": "b7bab9bf9cf85f0f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:16.542592Z",
     "start_time": "2025-07-25T08:51:12.536704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for text in dataset['text']:\n",
    "    text_vocab.addText(text)\n",
    "\n",
    "for title in dataset['title']:\n",
    "    title_vocab.addText(title)"
   ],
   "id": "852c28e87423675e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:16.553554Z",
     "start_time": "2025-07-25T08:51:16.550565Z"
    }
   },
   "cell_type": "code",
   "source": "text_vocab.__str__(), title_vocab.__str__()",
   "id": "744bafb50cbed8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Vocab(name='text', n_words=100000, \", \"Vocab(name='title', n_words=19534, \")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:16.562134Z",
     "start_time": "2025-07-25T08:51:16.560085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ],
   "id": "876bda39f0cca67d",
   "outputs": [],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
