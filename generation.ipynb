{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:08.790555Z",
     "start_time": "2025-07-25T08:51:08.785496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "bbb7bed3664fb591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:45:11.794717Z",
     "start_time": "2025-07-26T07:45:07.109585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('data/data_tokenize.csv')\n",
    "pairs = list(dataset[[\"title\", \"text\"]].itertuples(index=False, name=None))"
   ],
   "id": "d32ab7766f117c02",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:12.524282Z",
     "start_time": "2025-07-25T08:51:12.522993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sos_token = 0\n",
    "eos_token = 1\n",
    "MAX_VOCAB_SIZE = 100_000"
   ],
   "id": "494f3908570a88c1",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Работа с данными",
   "id": "b19158c090ab7cd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Словарь частот",
   "id": "fc6eb2179a03ea77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:58:23.160564Z",
     "start_time": "2025-07-26T07:58:23.149078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    \"\"\"Создаёт словари с частотами слов на основе входных данных\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<pad>\": 0, \"<unk>\": 1, \"sos\": 2, \"eos\": 3}\n",
    "        self.word2count = {\"<pad>\": 0, \"<unk>\": 0, \"sos\": 0, \"eos\": 0}\n",
    "        self.index2word = {0: \"<pad>\", 1: \"<unk>\", 2: \"sos\", 3: \"eos\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "        self._temp_word_counts = {}\n",
    "\n",
    "    def addText(self, text: str):\n",
    "        \"\"\"Для каждого слова в тексте добавляет его во временный счётчик\"\"\"\n",
    "        for word in text.split():\n",
    "            self._temp_word_counts[word] = self._temp_word_counts.get(word, 0) + 1\n",
    "\n",
    "    def build_vocab(self):\n",
    "        \"\"\"Строит финальный словарь после подсчёта всех слов\"\"\"\n",
    "        sorted_words = sorted(self._temp_word_counts.items(),\n",
    "                            key=lambda x: x[1],\n",
    "                            reverse=True)\n",
    "\n",
    "        for word, count in sorted_words[:MAX_VOCAB_SIZE - 4]:\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.word2count[word] = count\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "\n",
    "        for word, count in sorted_words[MAX_VOCAB_SIZE - 4:]:\n",
    "            self.word2count[\"<unk>\"] += count\n",
    "\n",
    "    def word_to_index(self, word: str) -> int:\n",
    "        \"\"\"Возвращает индекс слова или <unk>\"\"\"\n",
    "        return self.word2index.get(word, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def index_to_word(self, index: int) -> str:\n",
    "        \"\"\"Возвращает слово по индексу\"\"\"\n",
    "        return self.index2word.get(index, self.index2word[\"<unk>\"])\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Строковое представление словаря\"\"\"\n",
    "        return (\n",
    "            f\"Vocab(name='{self.name}', \"\n",
    "            f\"n_words={self.n_words}, \"\n",
    "        )"
   ],
   "id": "af697d8019de7b60",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:12.534622Z",
     "start_time": "2025-07-25T08:51:12.533219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_vocab = Vocab(\"title\")\n",
    "text_vocab = Vocab(\"text\")"
   ],
   "id": "b7bab9bf9cf85f0f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:16.542592Z",
     "start_time": "2025-07-25T08:51:12.536704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for text in dataset['text']:\n",
    "    text_vocab.addText(text)\n",
    "\n",
    "for title in dataset['title']:\n",
    "    title_vocab.addText(title)\n",
    "\n",
    "text_vocab.build_vocab()\n",
    "title_vocab.build_vocab()"
   ],
   "id": "852c28e87423675e",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:16.553554Z",
     "start_time": "2025-07-25T08:51:16.550565Z"
    }
   },
   "cell_type": "code",
   "source": "text_vocab.__str__(), title_vocab.__str__()",
   "id": "744bafb50cbed8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Vocab(name='text', n_words=100000, \", \"Vocab(name='title', n_words=19534, \")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Преобразование текста в датасет",
   "id": "30166912bd00d08f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def text_to_tensor(text: str, vocab: Vocab, add_sos_eos=True) -> torch.Tensor:\n",
    "    \"\"\"Преобразует текст в тензоры\"\"\"\n",
    "    tokens = text.strip().split()\n",
    "    indices = [vocab.word_to_index(w) for w in tokens]\n",
    "\n",
    "    if add_sos_eos:\n",
    "        indices = [vocab.word2index[\"<sos>\"]] + indices + [vocab.word2index[\"<eos>\"]]\n",
    "\n",
    "    return torch.tensor(indices, dtype=torch.long)\n"
   ],
   "id": "97e9048e47fad56b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, pairs: list[tuple[str, str]], input_vocab: Vocab, output_vocab: Vocab):\n",
    "        \"\"\"\n",
    "            pairs — список пар (название, текст),\n",
    "            input_vocab - словарь с частотами слов из текстов,\n",
    "            output_vocab - словарь с частотами слов из названий\n",
    "        \"\"\"\n",
    "        self.pairs = pairs\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title, text = self.pairs[idx]\n",
    "        input_tensor = text_to_tensor(text, self.input_vocab, add_sos_eos=False)\n",
    "        target_tensor = text_to_tensor(title, self.output_vocab, add_sos_eos=False)\n",
    "        return input_tensor, target_tensor\n"
   ],
   "id": "cd131f5993493712"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def collate_fn(batch: List[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    batch: list of (input_tensor, target_tensor)\n",
    "    Returns:\n",
    "        input_padded: [batch, src_len]\n",
    "        target_padded: [batch, trg_len]\n",
    "    \"\"\"\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_padded = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "\n",
    "    return src_padded, trg_padded\n"
   ],
   "id": "69762e8b16737afb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Модель seq2seq",
   "id": "789cf67de81efcf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Энкодер для seq2seq",
   "id": "721ebb0bf826a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:51:16.562134Z",
     "start_time": "2025-07-25T08:51:16.560085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ],
   "id": "876bda39f0cca67d",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Декодер для seq2seq",
   "id": "675fe048e3c70629"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ],
   "id": "a16bdbd14838a2c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Модель",
   "id": "a48522022988539d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hid_dim, \"Hidden dimensions must match!\"\n",
    "        assert decoder.n_layers == 1, \"Encoder must produce compatible layers for decoder\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0]\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n"
   ],
   "id": "112642599d19c612"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
