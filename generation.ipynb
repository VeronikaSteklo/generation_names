{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:05:58.746343Z",
     "start_time": "2025-07-29T08:05:58.743524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "bbb7bed3664fb591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:43.436123Z",
     "start_time": "2025-07-29T08:04:39.851200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('data/data_tokenize.csv')\n",
    "pairs = list(dataset[[\"title\", \"text\"]].itertuples(index=False, name=None))\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)"
   ],
   "id": "d32ab7766f117c02",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:43.447984Z",
     "start_time": "2025-07-29T08:04:43.446175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sos_token = 0\n",
    "eos_token = 1\n",
    "MAX_VOCAB_SIZE = 30_000\n",
    "\n",
    "MAX_INPUT_LEN = 300\n",
    "MAX_TARGET_LEN = 30\n"
   ],
   "id": "494f3908570a88c1",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Работа с данными",
   "id": "b19158c090ab7cd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Словарь частот",
   "id": "fc6eb2179a03ea77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:43.453827Z",
     "start_time": "2025-07-29T08:04:43.450477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    \"\"\"Создаёт словари с частотами слов на основе входных данных\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<pad>\": 0, \"<unk>\": 1, \"sos\": 2, \"eos\": 3}\n",
    "        self.word2count = {\"<pad>\": 0, \"<unk>\": 0, \"sos\": 0, \"eos\": 0}\n",
    "        self.index2word = {0: \"<pad>\", 1: \"<unk>\", 2: \"sos\", 3: \"eos\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "        self._temp_word_counts = {}\n",
    "\n",
    "    def addText(self, text: str):\n",
    "        \"\"\"Для каждого слова в тексте добавляет его во временный счётчик\"\"\"\n",
    "        for word in text.split():\n",
    "            self._temp_word_counts[word] = self._temp_word_counts.get(word, 0) + 1\n",
    "\n",
    "    def build_vocab(self):\n",
    "        \"\"\"Строит финальный словарь после подсчёта всех слов\"\"\"\n",
    "        sorted_words = sorted(self._temp_word_counts.items(),\n",
    "                            key=lambda x: x[1],\n",
    "                            reverse=True)\n",
    "\n",
    "        for word, count in sorted_words[:MAX_VOCAB_SIZE - 4]:\n",
    "            if word not in self.word2index:\n",
    "                if count > 10:\n",
    "                    self.word2index[word] = self.n_words\n",
    "                    self.word2count[word] = count\n",
    "                    self.index2word[self.n_words] = word\n",
    "                    self.n_words += 1\n",
    "                else:\n",
    "                    self.word2count[\"<unk>\"] += count\n",
    "\n",
    "        for word, count in sorted_words[MAX_VOCAB_SIZE - 4:]:\n",
    "            self.word2count[\"<unk>\"] += count\n",
    "\n",
    "    def word_to_index(self, word: str) -> int:\n",
    "        \"\"\"Возвращает индекс слова или <unk>\"\"\"\n",
    "        return self.word2index.get(word, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def index_to_word(self, index: int) -> str:\n",
    "        \"\"\"Возвращает слово по индексу\"\"\"\n",
    "        return self.index2word.get(index, self.index2word[\"<unk>\"])\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Строковое представление словаря\"\"\"\n",
    "        return (\n",
    "            f\"Vocab(name='{self.name}', \"\n",
    "            f\"n_words={self.n_words}, \"\n",
    "        )"
   ],
   "id": "af697d8019de7b60",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:43.468961Z",
     "start_time": "2025-07-29T08:04:43.457315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_vocab = Vocab(\"title\")\n",
    "text_vocab = Vocab(\"text\")"
   ],
   "id": "b7bab9bf9cf85f0f",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:48.940962Z",
     "start_time": "2025-07-29T08:04:43.474280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for text in dataset['text']:\n",
    "    text_vocab.addText(text)\n",
    "\n",
    "for title in dataset['title']:\n",
    "    title_vocab.addText(title)\n",
    "\n",
    "text_vocab.build_vocab()\n",
    "title_vocab.build_vocab()"
   ],
   "id": "852c28e87423675e",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:48.952036Z",
     "start_time": "2025-07-29T08:04:48.949866Z"
    }
   },
   "cell_type": "code",
   "source": "text_vocab.__str__(), title_vocab.__str__()",
   "id": "744bafb50cbed8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Vocab(name='text', n_words=30000, \", \"Vocab(name='title', n_words=555, \")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.346226Z",
     "start_time": "2025-07-29T08:04:48.959022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = Vocab(\"input\")\n",
    "target_vocab = Vocab(\"target\")\n",
    "\n",
    "for title, text in train_pairs:\n",
    "    input_vocab.addText(text)\n",
    "    target_vocab.addText(title)\n",
    "\n",
    "input_vocab.build_vocab()\n",
    "target_vocab.build_vocab()\n"
   ],
   "id": "9bd4598240aaaf2",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Преобразование текста в датасет",
   "id": "30166912bd00d08f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.354736Z",
     "start_time": "2025-07-29T08:04:53.352920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_tensor(text: str, vocab: Vocab, add_sos_eos=True, max_len: int | None = None, truncate_from_start=False) -> torch.Tensor:\n",
    "    \"\"\"Преобразует текст в тензоры, с опциональной обрезкой\"\"\"\n",
    "    tokens = text.strip().split()\n",
    "\n",
    "    # Обрезка по длине\n",
    "    if max_len is not None:\n",
    "        if truncate_from_start:\n",
    "            tokens = tokens[-max_len:]  # последние max_len токенов\n",
    "        else:\n",
    "            tokens = tokens[:max_len]   # первые max_len токенов\n",
    "\n",
    "    indices = [vocab.word_to_index(w) for w in tokens]\n",
    "\n",
    "    if add_sos_eos:\n",
    "        indices = [vocab.word2index[\"<sos>\"]] + indices + [vocab.word2index[\"<eos>\"]]\n",
    "\n",
    "    return torch.tensor(indices, dtype=torch.long)\n"
   ],
   "id": "97e9048e47fad56b",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.358555Z",
     "start_time": "2025-07-29T08:04:53.356888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, pairs: list[tuple[str, str]], input_vocab: Vocab, output_vocab: Vocab):\n",
    "        \"\"\"\n",
    "            pairs — список пар (название, текст),\n",
    "            input_vocab - словарь с частотами слов из текстов,\n",
    "            output_vocab - словарь с частотами слов из названий\n",
    "        \"\"\"\n",
    "        self.pairs = pairs\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title, text = self.pairs[idx]\n",
    "        input_tensor = text_to_tensor(text, self.input_vocab, add_sos_eos=False, max_len=300)\n",
    "        target_tensor = text_to_tensor(title, self.output_vocab, add_sos_eos=False, max_len=30)\n",
    "        return input_tensor, target_tensor\n"
   ],
   "id": "cd131f5993493712",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.362703Z",
     "start_time": "2025-07-29T08:04:53.360587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch: List[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    batch: list of (input_tensor, target_tensor)\n",
    "    Returns:\n",
    "        input_padded: [batch, src_len]\n",
    "        target_padded: [batch, trg_len]\n",
    "    \"\"\"\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_padded = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "\n",
    "    return src_padded, trg_padded\n"
   ],
   "id": "69762e8b16737afb",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Модель seq2seq",
   "id": "789cf67de81efcf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Энкодер для seq2seq",
   "id": "721ebb0bf826a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.367269Z",
     "start_time": "2025-07-29T08:04:53.365435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.3):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ],
   "id": "876bda39f0cca67d",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Декодер для seq2seq",
   "id": "675fe048e3c70629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.371219Z",
     "start_time": "2025-07-29T08:04:53.369431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ],
   "id": "a16bdbd14838a2c0",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Модель",
   "id": "a48522022988539d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.375192Z",
     "start_time": "2025-07-29T08:04:53.373226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hid_dim, \"Hidden dimensions must match!\"\n",
    "        assert decoder.n_layers == 1, \"Encoder must produce compatible layers for decoder\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.1):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # [batch_size, trg_len, vocab_size]\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n"
   ],
   "id": "112642599d19c612",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "вайбкодинг",
   "id": "28ac6c37314af6ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.378249Z",
     "start_time": "2025-07-29T08:04:53.376973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAD_IDX = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ],
   "id": "9949ad8d773c9284",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:17:04.952479Z",
     "start_time": "2025-07-29T08:17:04.947956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip=1.0, device='cpu'):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_grad_norm = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for src, trg in dataloader:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        # output: [batch_size, trg_len, output_dim]\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient monitoring and manipulation\n",
    "        current_grad_norm = 0\n",
    "        non_zero_grads = 0\n",
    "\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                # Apply gradient boost only to small gradients\n",
    "                grad_mean = p.grad.abs().mean()\n",
    "                if grad_mean < 0.01:  # Only boost small gradients\n",
    "                    p.grad *= 2.0\n",
    "\n",
    "                current_grad_norm += p.grad.norm().item()\n",
    "                non_zero_grads += 1\n",
    "\n",
    "        # Dynamic gradient clipping\n",
    "        avg_grad_norm = current_grad_norm / max(1, non_zero_grads)\n",
    "        dynamic_clip = min(clip, avg_grad_norm * 1.5)  # Adaptive clipping\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), dynamic_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        total_grad_norm += current_grad_norm\n",
    "        batch_count += 1\n",
    "\n",
    "        # Print gradient stats every 10 batches\n",
    "        if batch_count % 100 == 0:\n",
    "            print(f\"Batch {batch_count}: Avg Grad Norm: {current_grad_norm/non_zero_grads:.5f}\")\n",
    "\n",
    "    # print(f\"Epoch complete - Avg Gradient Norm: {avg_grad:.5f}\")\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ],
   "id": "e8df166828cb1d87",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:04:53.385818Z",
     "start_time": "2025-07-29T08:04:53.384171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, dataloader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ],
   "id": "df9e79840b19575e",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:05:06.657936Z",
     "start_time": "2025-07-29T08:05:06.654405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 512\n",
    "EMB_DIM = 128\n",
    "ENC_DROPOUT = 0.4\n",
    "DEC_DROPOUT = 0.4\n",
    "N_LAYERS = 1"
   ],
   "id": "6c1a61a9ca2a86c4",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:05:07.394334Z",
     "start_time": "2025-07-29T08:05:07.264376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n"
   ],
   "id": "2f810147d4ff1457",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:05:09.937434Z",
     "start_time": "2025-07-29T08:05:09.933993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TitleDataset(train_pairs, input_vocab, target_vocab)\n",
    "val_dataset = TitleDataset(val_pairs, input_vocab, target_vocab)"
   ],
   "id": "95f34a5a8ce4a7f2",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:05:10.282033Z",
     "start_time": "2025-07-29T08:05:10.276741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "31fc7d6ad82ad245",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-29T08:28:42.923175Z",
     "start_time": "2025-07-29T08:17:08.078964Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAD_IDX = target_vocab.word2index[\"<pad>\"]\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.3,\n",
    "    patience=1,\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip=1.0, device=device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} \"\n",
    "        f\"| LR: {optimizer.param_groups[0]['lr']:.6f} | Time: {epoch_time}s\"\n",
    "    )"
   ],
   "id": "25f84db947334638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100: Avg Grad Norm: 0.17501\n",
      "Batch 200: Avg Grad Norm: 0.19258\n",
      "Batch 300: Avg Grad Norm: 0.17408\n",
      "Batch 400: Avg Grad Norm: 0.25695\n",
      "Epoch 01 | Train Loss: 3.247 | Val Loss: 3.206 | LR: 0.000300 | Time: 130.6863968372345s\n",
      "Batch 100: Avg Grad Norm: 0.18536\n",
      "Batch 200: Avg Grad Norm: 0.22747\n",
      "Batch 300: Avg Grad Norm: 0.20746\n",
      "Batch 400: Avg Grad Norm: 0.21459\n",
      "Epoch 02 | Train Loss: 3.220 | Val Loss: 3.205 | LR: 0.000300 | Time: 131.82858085632324s\n",
      "Batch 100: Avg Grad Norm: 0.22673\n",
      "Batch 200: Avg Grad Norm: 0.21623\n",
      "Batch 300: Avg Grad Norm: 0.24971\n",
      "Batch 400: Avg Grad Norm: 0.23240\n",
      "Epoch 03 | Train Loss: 3.194 | Val Loss: 3.205 | LR: 0.000090 | Time: 130.92090392112732s\n",
      "Batch 100: Avg Grad Norm: 0.24335\n",
      "Batch 200: Avg Grad Norm: 0.21437\n",
      "Batch 300: Avg Grad Norm: 0.30141\n",
      "Batch 400: Avg Grad Norm: 0.33622\n",
      "Epoch 04 | Train Loss: 3.139 | Val Loss: 3.203 | LR: 0.000090 | Time: 130.72929525375366s\n",
      "Batch 100: Avg Grad Norm: 0.32219\n",
      "Batch 200: Avg Grad Norm: 0.27892\n",
      "Batch 300: Avg Grad Norm: 0.27492\n",
      "Batch 400: Avg Grad Norm: 0.26445\n",
      "Epoch 05 | Train Loss: 3.116 | Val Loss: 3.208 | LR: 0.000027 | Time: 131.15988612174988s\n",
      "Batch 100: Avg Grad Norm: 0.31122\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[77]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m, num_epochs + \u001B[32m1\u001B[39m):\n\u001B[32m     16\u001B[39m     start_time = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     train_loss = \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclip\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     18\u001B[39m     val_loss = evaluate(model, val_loader, criterion, device)\n\u001B[32m     19\u001B[39m     epoch_time = time.time() - start_time\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[76]\u001B[39m\u001B[32m, line 21\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(model, dataloader, optimizer, criterion, clip, device)\u001B[39m\n\u001B[32m     18\u001B[39m trg = trg[:, \u001B[32m1\u001B[39m:].reshape(-\u001B[32m1\u001B[39m)\n\u001B[32m     20\u001B[39m loss = criterion(output, trg)\n\u001B[32m---> \u001B[39m\u001B[32m21\u001B[39m \u001B[43mloss\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Gradient monitoring and manipulation\u001B[39;00m\n\u001B[32m     24\u001B[39m current_grad_norm = \u001B[32m0\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/_tensor.py:648\u001B[39m, in \u001B[36mTensor.backward\u001B[39m\u001B[34m(self, gradient, retain_graph, create_graph, inputs)\u001B[39m\n\u001B[32m    638\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    639\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[32m    640\u001B[39m         Tensor.backward,\n\u001B[32m    641\u001B[39m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[32m   (...)\u001B[39m\u001B[32m    646\u001B[39m         inputs=inputs,\n\u001B[32m    647\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m648\u001B[39m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mautograd\u001B[49m\u001B[43m.\u001B[49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    649\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43minputs\u001B[49m\n\u001B[32m    650\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/__init__.py:353\u001B[39m, in \u001B[36mbackward\u001B[39m\u001B[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[39m\n\u001B[32m    348\u001B[39m     retain_graph = create_graph\n\u001B[32m    350\u001B[39m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[32m    351\u001B[39m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    354\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    356\u001B[39m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    357\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    358\u001B[39m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    360\u001B[39m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    361\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/autograd/graph.py:824\u001B[39m, in \u001B[36m_engine_run_backward\u001B[39m\u001B[34m(t_outputs, *args, **kwargs)\u001B[39m\n\u001B[32m    822\u001B[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[32m    823\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m824\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_execution_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[32m    825\u001B[39m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m    826\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[32m    827\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    828\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\n",
   "id": "79ca8148405a20dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
