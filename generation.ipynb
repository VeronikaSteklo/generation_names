{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:06.127884Z",
     "start_time": "2025-07-30T08:34:06.123040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "id": "bbb7bed3664fb591",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:09.798843Z",
     "start_time": "2025-07-30T08:34:06.152752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = pd.read_csv('data/data_tokenize.csv')\n",
    "pairs = list(dataset[[\"title\", \"text\"]].itertuples(index=False, name=None))\n",
    "train_pairs, val_pairs = train_test_split(pairs, test_size=0.1, random_state=42)"
   ],
   "id": "d32ab7766f117c02",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:09.807107Z",
     "start_time": "2025-07-30T08:34:09.805709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sos_token = 0\n",
    "eos_token = 1\n",
    "MAX_VOCAB_SIZE = 30_000\n",
    "\n",
    "MAX_INPUT_LEN = 300\n",
    "MAX_TARGET_LEN = 30\n"
   ],
   "id": "494f3908570a88c1",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Работа с данными",
   "id": "b19158c090ab7cd9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Словарь частот",
   "id": "fc6eb2179a03ea77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:09.812614Z",
     "start_time": "2025-07-30T08:34:09.809280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    \"\"\"Создаёт словари с частотами слов на основе входных данных\"\"\"\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"<pad>\": 0, \"<unk>\": 1, \"sos\": 2, \"eos\": 3}\n",
    "        self.word2count = {\"<pad>\": 0, \"<unk>\": 0, \"sos\": 0, \"eos\": 0}\n",
    "        self.index2word = {0: \"<pad>\", 1: \"<unk>\", 2: \"sos\", 3: \"eos\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "        self._temp_word_counts = {}\n",
    "\n",
    "    def addText(self, text: str):\n",
    "        \"\"\"Для каждого слова в тексте добавляет его во временный счётчик\"\"\"\n",
    "        for word in text.split():\n",
    "            self._temp_word_counts[word] = self._temp_word_counts.get(word, 0) + 1\n",
    "\n",
    "    def build_vocab(self, is_text: bool = False):\n",
    "        \"\"\"Строит финальный словарь после подсчёта всех слов\"\"\"\n",
    "        sorted_words = sorted(self._temp_word_counts.items(),\n",
    "                            key=lambda x: x[1],\n",
    "                            reverse=True)\n",
    "\n",
    "        for word, count in sorted_words[:MAX_VOCAB_SIZE - 4]:\n",
    "            if word not in self.word2index:\n",
    "                if is_text:\n",
    "                    if count > 10:\n",
    "                        self.word2index[word] = self.n_words\n",
    "                        self.word2count[word] = count\n",
    "                        self.index2word[self.n_words] = word\n",
    "                        self.n_words += 1\n",
    "                    else:\n",
    "                        self.word2count[\"<unk>\"] += count\n",
    "\n",
    "                else:\n",
    "                    if count > 5:\n",
    "                        self.word2index[word] = self.n_words\n",
    "                        self.word2count[word] = count\n",
    "                        self.index2word[self.n_words] = word\n",
    "                        self.n_words += 1\n",
    "                    else:\n",
    "                        self.word2count[\"<unk>\"] += count\n",
    "\n",
    "        for word, count in sorted_words[MAX_VOCAB_SIZE - 4:]:\n",
    "            self.word2count[\"<unk>\"] += count\n",
    "\n",
    "    def word_to_index(self, word: str) -> int:\n",
    "        \"\"\"Возвращает индекс слова или <unk>\"\"\"\n",
    "        return self.word2index.get(word, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def index_to_word(self, index: int) -> str:\n",
    "        \"\"\"Возвращает слово по индексу\"\"\"\n",
    "        return self.index2word.get(index, self.word2index[\"<unk>\"])\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Строковое представление словаря\"\"\"\n",
    "        return (\n",
    "            f\"Vocab(name='{self.name}', \"\n",
    "            f\"n_words={self.n_words}, \"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2index)"
   ],
   "id": "af697d8019de7b60",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:09.826013Z",
     "start_time": "2025-07-30T08:34:09.814725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "title_vocab = Vocab(\"title\")\n",
    "text_vocab = Vocab(\"text\")"
   ],
   "id": "b7bab9bf9cf85f0f",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:15.056554Z",
     "start_time": "2025-07-30T08:34:09.828189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for text in dataset['text']:\n",
    "    text_vocab.addText(text)\n",
    "\n",
    "for title in dataset['title']:\n",
    "    title_vocab.addText(title)\n",
    "\n",
    "text_vocab.build_vocab()\n",
    "title_vocab.build_vocab()"
   ],
   "id": "852c28e87423675e",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:15.066429Z",
     "start_time": "2025-07-30T08:34:15.064537Z"
    }
   },
   "cell_type": "code",
   "source": "text_vocab.__str__(), title_vocab.__str__()",
   "id": "744bafb50cbed8f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Vocab(name='text', n_words=30000, \", \"Vocab(name='title', n_words=19534, \")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.463545Z",
     "start_time": "2025-07-30T08:34:15.072279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_vocab = Vocab(\"input\")\n",
    "target_vocab = Vocab(\"target\")\n",
    "\n",
    "for title, text in train_pairs:\n",
    "    input_vocab.addText(text)\n",
    "    target_vocab.addText(title)\n",
    "\n",
    "input_vocab.build_vocab(is_text=True)\n",
    "target_vocab.build_vocab(is_text=False)\n"
   ],
   "id": "9bd4598240aaaf2",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Преобразование текста в датасет",
   "id": "30166912bd00d08f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.472190Z",
     "start_time": "2025-07-30T08:34:19.470439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def text_to_tensor(text: str, vocab: Vocab, add_sos_eos=True, max_len: int | None = None, truncate_from_start=False) -> torch.Tensor:\n",
    "    \"\"\"Преобразует текст в тензоры, с опциональной обрезкой\"\"\"\n",
    "    tokens = text.strip().split()\n",
    "\n",
    "    if max_len is not None:\n",
    "        if truncate_from_start:\n",
    "            tokens = tokens[-max_len:]\n",
    "        else:\n",
    "            tokens = tokens[:max_len]\n",
    "\n",
    "    indices = [vocab.word_to_index(w) for w in tokens]\n",
    "\n",
    "    if add_sos_eos:\n",
    "        indices = [vocab.word2index[\"<sos>\"]] + indices + [vocab.word2index[\"<eos>\"]]\n",
    "\n",
    "    return torch.tensor(indices, dtype=torch.long)\n"
   ],
   "id": "97e9048e47fad56b",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.476063Z",
     "start_time": "2025-07-30T08:34:19.474222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TitleDataset(Dataset):\n",
    "    def __init__(self, pairs: list[tuple[str, str]], input_vocab: Vocab, output_vocab: Vocab):\n",
    "        \"\"\"\n",
    "            pairs — список пар (название, текст),\n",
    "            input_vocab - словарь с частотами слов из текстов,\n",
    "            output_vocab - словарь с частотами слов из названий\n",
    "        \"\"\"\n",
    "        self.pairs = pairs\n",
    "        self.input_vocab = input_vocab\n",
    "        self.output_vocab = output_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title, text = self.pairs[idx]\n",
    "        input_tensor = text_to_tensor(text, self.input_vocab, add_sos_eos=False, max_len=300)\n",
    "        target_tensor = text_to_tensor(title, self.output_vocab, add_sos_eos=False, max_len=30)\n",
    "        return input_tensor, target_tensor\n"
   ],
   "id": "cd131f5993493712",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.479564Z",
     "start_time": "2025-07-30T08:34:19.478131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collate_fn(batch: List[tuple[str, str]]):\n",
    "    \"\"\"\n",
    "    batch: list of (input_tensor, target_tensor)\n",
    "    Returns:\n",
    "        input_padded: [batch, src_len]\n",
    "        target_padded: [batch, trg_len]\n",
    "    \"\"\"\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, padding_value=0, batch_first=True)\n",
    "    trg_padded = pad_sequence(trg_batch, padding_value=0, batch_first=True)\n",
    "\n",
    "    return src_padded, trg_padded\n"
   ],
   "id": "69762e8b16737afb",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Модель seq2seq",
   "id": "789cf67de81efcf7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Энкодер для seq2seq",
   "id": "721ebb0bf826a5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.482830Z",
     "start_time": "2025-07-30T08:34:19.481329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p=0.3):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        return output, (hidden, cell)"
   ],
   "id": "876bda39f0cca67d",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Декодер для seq2seq",
   "id": "675fe048e3c70629"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.486377Z",
     "start_time": "2025-07-30T08:34:19.484654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction, hidden, cell"
   ],
   "id": "a16bdbd14838a2c0",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Модель",
   "id": "a48522022988539d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.489854Z",
     "start_time": "2025-07-30T08:34:19.488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hid_dim, \"Hidden dimensions must match!\"\n",
    "        assert decoder.n_layers == 1, \"Encoder must produce compatible layers for decoder\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.1):\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # [batch_size, trg_len, vocab_size]\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        encoder_outputs, (hidden, cell) = self.encoder(src)\n",
    "\n",
    "        input = trg[:, 0]  # <sos>\n",
    "\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[:, t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs\n",
    "\n"
   ],
   "id": "112642599d19c612",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "вайбкодинг",
   "id": "28ac6c37314af6ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.492693Z",
     "start_time": "2025-07-30T08:34:19.491479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PAD_IDX = 0\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ],
   "id": "9949ad8d773c9284",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.496216Z",
     "start_time": "2025-07-30T08:34:19.494083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, dataloader, optimizer, criterion, clip=1.0, device='cpu'):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_grad_norm = 0\n",
    "    batch_count = 0\n",
    "\n",
    "    for src, trg in dataloader:\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        current_grad_norm = 0\n",
    "        non_zero_grads = 0\n",
    "\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                grad_mean = p.grad.abs().mean()\n",
    "                if grad_mean < 0.01:\n",
    "                    p.grad *= 2.0\n",
    "\n",
    "                current_grad_norm += p.grad.norm().item()\n",
    "                non_zero_grads += 1\n",
    "\n",
    "        avg_grad_norm = current_grad_norm / max(1, non_zero_grads)\n",
    "        dynamic_clip = min(clip, avg_grad_norm * 1.5)\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), dynamic_clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        total_grad_norm += current_grad_norm\n",
    "        batch_count += 1\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ],
   "id": "e8df166828cb1d87",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.499494Z",
     "start_time": "2025-07-30T08:34:19.497945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, dataloader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n"
   ],
   "id": "df9e79840b19575e",
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.502478Z",
     "start_time": "2025-07-30T08:34:19.501138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "ENC_EMB_DIM = 128\n",
    "DEC_EMB_DIM = 128\n",
    "HID_DIM = 512\n",
    "EMB_DIM = 128\n",
    "ENC_DROPOUT = 0.4\n",
    "DEC_DROPOUT = 0.4\n",
    "N_LAYERS = 1"
   ],
   "id": "6c1a61a9ca2a86c4",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.643238Z",
     "start_time": "2025-07-30T08:34:19.505076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n"
   ],
   "id": "2f810147d4ff1457",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.650368Z",
     "start_time": "2025-07-30T08:34:19.648725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TitleDataset(train_pairs, input_vocab, target_vocab)\n",
    "val_dataset = TitleDataset(val_pairs, input_vocab, target_vocab)"
   ],
   "id": "95f34a5a8ce4a7f2",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:34:19.654118Z",
     "start_time": "2025-07-30T08:34:19.652398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ],
   "id": "31fc7d6ad82ad245",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:53:55.231887Z",
     "start_time": "2025-07-30T08:34:19.656966Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AD_IDX = target_vocab.word2index[\"<pad>\"]\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.3,\n",
    "    patience=1,\n",
    "    threshold=0.01\n",
    ")\n",
    "\n",
    "early_stopping_patience = 3\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "best_model_state = None\n",
    "previous_val_loss = None\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, clip=1.0, device=device)\n",
    "    val_loss = evaluate(model, val_loader, criterion, device)\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if previous_val_loss is not None and (abs(val_loss - previous_val_loss) <= 0.01 or val_loss > previous_val_loss):\n",
    "        epochs_without_improvement += 1\n",
    "    else:\n",
    "        epochs_without_improvement = 0\n",
    "\n",
    "    previous_val_loss = val_loss\n",
    "\n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(f\"Ранний останов после {epoch:02} эпох (val_loss изменяется менее чем на ±0.01 в течение {early_stopping_patience} эпох)!\")\n",
    "        torch.save(model.state_dict(), 'models/best_model.pt')\n",
    "        break\n",
    "\n",
    "    print(\n",
    "        f\"{epochs_without_improvement}\\n\"\n",
    "        f\"Epoch {epoch:02} | Train Loss: {train_loss:.3f} | Val Loss: {val_loss:.3f} \"\n",
    "        f\"| LR: {optimizer.param_groups[0]['lr']:.6f} | Time: {epoch_time:3f}s\"\n",
    "    )"
   ],
   "id": "25f84db947334638",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 01 | Train Loss: 7.620 | Val Loss: 7.451 | LR: 0.000300 | Time: 193.798814s\n",
      "0\n",
      "Epoch 02 | Train Loss: 7.130 | Val Loss: 7.425 | LR: 0.000300 | Time: 195.494848s\n",
      "0\n",
      "Epoch 03 | Train Loss: 6.940 | Val Loss: 7.391 | LR: 0.000090 | Time: 192.276566s\n",
      "1\n",
      "Epoch 04 | Train Loss: 6.711 | Val Loss: 7.398 | LR: 0.000090 | Time: 200.260401s\n",
      "2\n",
      "Epoch 05 | Train Loss: 6.638 | Val Loss: 7.403 | LR: 0.000027 | Time: 196.232395s\n",
      "Ранний останов после 06 эпох (val_loss изменяется менее чем на ±0.01 в течение 3 эпох)!\n"
     ]
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:53:55.313327Z",
     "start_time": "2025-07-30T08:53:55.311841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n"
   ],
   "id": "79ca8148405a20dc",
   "outputs": [],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:58:17.063425Z",
     "start_time": "2025-07-30T08:58:17.057394Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_title(model, input_text, input_vocab, target_vocab, max_len=50, device=\"cpu\", temperature=0.7):\n",
    "    model.eval()\n",
    "\n",
    "    tokens = re.findall(r\"\\w+|[.,!?;]\", input_text.lower())\n",
    "    src_indexes = [input_vocab.word2index.get(token, input_vocab.word2index[\"<unk>\"]) for token in tokens]\n",
    "\n",
    "    if not src_indexes:\n",
    "        return \"Невозможно проанализировать текст\"\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = [target_vocab.word2index[\"<sos>\"]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "\n",
    "        output_dist = output[0,-1].div(temperature).exp()\n",
    "        pred_token = torch.multinomial(output_dist, 1).item()\n",
    "\n",
    "        if pred_token == target_vocab.word2index[\"<eos>\"] or (i > 10 and len(set(trg_indexes[-5:])) < 2):\n",
    "            break\n",
    "\n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "    filtered = []\n",
    "    for idx in trg_indexes[1:]:\n",
    "        word = target_vocab.index_to_word(idx)\n",
    "        if word not in [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"] and not word.isdigit():\n",
    "            filtered.append(word)\n",
    "\n",
    "    result = ' '.join(filtered).capitalize()\n",
    "    result = re.sub(r'\\s([?.!,](?:\\s|$))', r'\\1', result)\n",
    "\n",
    "    return result"
   ],
   "id": "2c9bbed6485fa289",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:58:57.651181Z",
     "start_time": "2025-07-30T08:58:19.111520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "INPUT_DIM = input_vocab.n_words\n",
    "OUTPUT_DIM = target_vocab.n_words\n",
    "HID_DIM = 512\n",
    "N_LAYERS = 1\n",
    "\n",
    "encoder = EncoderLSTM(INPUT_DIM, HID_DIM, dropout_p=0.4)\n",
    "decoder = Decoder(OUTPUT_DIM, 128, HID_DIM, N_LAYERS, 0.4)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "model.load_state_dict(torch.load('models/best_model.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Генератор названий\")\n",
    "print(\"Введите текст (или 'выход' для завершения):\")\n",
    "\n",
    "while True:\n",
    "    input_text = input(\"\\n> \")\n",
    "\n",
    "    if input_text.lower() in ['выход', 'exit', 'quit']:\n",
    "        break\n",
    "\n",
    "    if len(input_text.strip()) == 0:\n",
    "        print(\"Пожалуйста, введите текст.\")\n",
    "        continue\n",
    "\n",
    "    title = generate_title(model, input_text, input_vocab, target_vocab, device=device)\n",
    "    print(\"\\nСгенерированное название:\")\n",
    "    print(title)\n",
    "    print(\"\\nВведите следующий текст или 'выход' для завершения:\")\n"
   ],
   "id": "d1a2b381fdee660",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Генератор заголовков новостей\n",
      "Введите текст новости (или 'выход' для завершения):\n",
      "\n",
      "Сгенерированный заголовок:\n",
      "Сердцем волк\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированный заголовок:\n",
      "Qu корнеслов ценностях\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n",
      "\n",
      "Сгенерированный заголовок:\n",
      "Шнурки безвременье. .\n",
      "\n",
      "Введите следующий текст или 'выход' для завершения:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[107]\u001B[39m\u001B[32m, line 17\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mВведите текст новости (или \u001B[39m\u001B[33m'\u001B[39m\u001B[33mвыход\u001B[39m\u001B[33m'\u001B[39m\u001B[33m для завершения):\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m     input_text = \u001B[38;5;28;43minput\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[38;5;130;43;01m\\n\u001B[39;49;00m\u001B[33;43m> \u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m input_text.lower() \u001B[38;5;129;01min\u001B[39;00m [\u001B[33m'\u001B[39m\u001B[33mвыход\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mexit\u001B[39m\u001B[33m'\u001B[39m, \u001B[33m'\u001B[39m\u001B[33mquit\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     20\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001B[39m, in \u001B[36mKernel.raw_input\u001B[39m\u001B[34m(self, prompt)\u001B[39m\n\u001B[32m   1280\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mraw_input was called, but this frontend does not support input requests.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1281\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m StdinNotImplementedError(msg)\n\u001B[32m-> \u001B[39m\u001B[32m1282\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_input_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1283\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1284\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_parent_ident\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1285\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mget_parent\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mshell\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   1286\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpassword\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m   1287\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001B[39m, in \u001B[36mKernel._input_request\u001B[39m\u001B[34m(self, prompt, ident, parent, password)\u001B[39m\n\u001B[32m   1322\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[32m   1323\u001B[39m     \u001B[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001B[39;00m\n\u001B[32m   1324\u001B[39m     msg = \u001B[33m\"\u001B[39m\u001B[33mInterrupted by user\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1325\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1326\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   1327\u001B[39m     \u001B[38;5;28mself\u001B[39m.log.warning(\u001B[33m\"\u001B[39m\u001B[33mInvalid Message:\u001B[39m\u001B[33m\"\u001B[39m, exc_info=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: Interrupted by user"
     ]
    }
   ],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:54:41.006002Z",
     "start_time": "2025-07-30T08:54:41.004113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Размер словаря:\", len(target_vocab))\n",
    "print(\"Примеры слов:\", [target_vocab.index_to_word(i) for i in range(10)])"
   ],
   "id": "d2b60dc46e62cbfc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 18040\n",
      "Примеры слов: ['<pad>', '<unk>', 'sos', 'eos', '<sos>', '<eos>', '.', ',', '...', 'и']\n"
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T08:54:41.027746Z",
     "start_time": "2025-07-30T08:54:41.026427Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "32eacf46ad395f63",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
